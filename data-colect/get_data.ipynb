{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import bs4, time, requests\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "import numpy as np\n",
    "\n",
    "import plotly\n",
    "from plotly.offline import plot_mpl\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "plotly.offline.init_notebook_mode(connected=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega todos os resultados do google\n",
    "class socialMediaScrapper():\n",
    "    def __init__(self, has_data=False):\n",
    "        if has_data != True: self.driver_() #inicia o navegador\n",
    "\n",
    "    def __call__(self):\n",
    "        #ao chamar como funcao ira fazer fazer a pesquisa, pegar os dados das redes sociais e tambem de anuncios\n",
    "        print('getting search results...')\n",
    "        self.saude_curitiba = self.googleSearch()\n",
    "        print('findind social media accounts...')\n",
    "        self.saude_curitiba = self.findSocialMediaAccounts(self.saude_curitiba)\n",
    "        print('getting instagram data...')\n",
    "        self.saude_curitiba = self.getInstagramData(self.saude_curitiba)\n",
    "        print('getting facebook data...')\n",
    "        self.saude_curitiba = self.getFacebookData(self.saude_curitiba)\n",
    "        print('getting ads data...')\n",
    "        self.saude_curitiba = self.getAdsData(self.saude_curitiba)\n",
    "        print('all done')\n",
    "        return self.saude_curitiba\n",
    "    \n",
    "    def driver_(self):\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"profile\")\n",
    "        options.add_argument(\"user-data-dir=./Browser/Profile\")\n",
    "        \n",
    "        if \"Windows\" in platform.platform():\n",
    "            executable_path = './Browser/Driver/Win/chromedriver.exe' \n",
    "            print('Platform: Windows')\n",
    "        else:\n",
    "            executable_path = './Browser/Driver/chromedriver'\n",
    "            \n",
    "        self.driver = webdriver.Chrome(executable_path=executable_path, options=options)\n",
    "\n",
    "        \n",
    "        \n",
    "    def nextPage(self):\n",
    "        # Procura o botao para a próxima página\n",
    "        htmlPage = bs4.BeautifulSoup(self.driver.page_source, features='html.parser')\n",
    "\n",
    "        button_status = htmlPage.find('button', {'jsaction':'pane.paginationSection.nextPage'})\n",
    "        button_next = htmlPage.find('span', {'class':'n7lv7yjyC35__button-next-icon'})\n",
    "        if button_status != None and button_status.get('disabled') == 'true':\n",
    "            return 'end'\n",
    "        elif button_next != None:\n",
    "            return 'next'\n",
    "\n",
    "    def typeResultList(self):\n",
    "        ''' encontra qual o tipo de resultados que o google devolveu\n",
    "            * ha resultados com o link direto\n",
    "            * ha resultados que precisa de um clique para acessar os dados\n",
    "        '''\n",
    "        htmlPage = bs4.BeautifulSoup(self.driver.page_source, features='html.parser')\n",
    "        route_button = htmlPage.find('div',{'class':'section-result-action-icon-container'})\n",
    "        if route_button != None:\n",
    "            return 'simple'\n",
    "        else:\n",
    "            return 'need click'\n",
    "    \n",
    "    def googleSearch(self, url=None, clean=True):\n",
    "        '''\n",
    "            * pode ser chamado sem url desde que esteja na aba da pesquisa\n",
    "            * clean=True para retornar os dados ja limpes pelo modulo ProcessData\n",
    "        '''\n",
    "        if url == None:\n",
    "            input('Aperte Enter quando já estiver na pesquisa que deseja capturar os dados: ')\n",
    "        else:\n",
    "            self.driver.get(url)\n",
    "            time.sleep(2)\n",
    "\n",
    "        # Verifica qual o tipo de resultados\n",
    "        if self.typeResultList() == 'need click':\n",
    "            # importa a outra classe para usar\n",
    "            moreActions = self.moreBrowseActions(self.driver)\n",
    "            simpleScrapp = False\n",
    "        else:\n",
    "            simpleScrapp  = True\n",
    "        \n",
    "        results = []\n",
    "        while True:\n",
    "            try:\n",
    "                htmlPage = bs4.BeautifulSoup(self.driver.page_source, features='html.parser')\n",
    "                if simpleScrapp == True:\n",
    "                    results.extend(htmlPage.find_all('div', {'class':'section-result'}))\n",
    "                else:\n",
    "                    click_error = 0\n",
    "                    for i in range(1, 21):\n",
    "                        if moreActions.clickResult(i) == False: click_error+=1\n",
    "                        if click_error >=2: break\n",
    "                        \n",
    "                        time.sleep(2)\n",
    "                        results.append(moreActions.dataFromClickedResult(i))\n",
    "                        moreActions.backToResults()\n",
    "                        time.sleep(1)\n",
    "                        \n",
    "                        \n",
    "                if self.nextPage() == 'end': \n",
    "                    break\n",
    "                else:\n",
    "                    next_page = self.driver.find_element_by_class_name('n7lv7yjyC35__button-next-icon')\n",
    "                    next_page.click()\n",
    "                    time.sleep(2)\n",
    "            except KeyboardInterrupt: \n",
    "                break\n",
    "            except Exception as error:\n",
    "                if htmlPage.find('div',{'class':'section-no-result noprint'}) != None: \n",
    "                    break\n",
    "                else:\n",
    "                    print('ERROR IN [socialMediaScrapper()] function: googleSearch()\\n')\n",
    "                    print(type(error), str(error))\n",
    "        \n",
    "        if simpleScrapp == False:\n",
    "            results = pd.DataFrame(results)\n",
    "            results.reset_index(drop=True, inplace=True)\n",
    "            return results\n",
    "        elif clean == False:\n",
    "            return list(set(results))\n",
    "        else:\n",
    "            clean = ProcessData()\n",
    "            return clean.googleSearchResults(results)\n",
    "        \n",
    "    class moreBrowseActions():\n",
    "        ''' acoes extras para o navegador caso os resultados nao estejam na lista e precise ser clicado'''\n",
    "        def __init__(self, driver):\n",
    "            self.driver = driver\n",
    "            \n",
    "        def clickResult(self, position):\n",
    "            ''' ira clicar no resultado e extrair os dados'''\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('//div[@data-result-index=' + str(position) + ']').click()\n",
    "                return True\n",
    "            except Exception as error:\n",
    "                if 'NoSuchElementException' in str(type(error)): return False\n",
    "                \n",
    "                print('ERROR IN [socialMediaScrapper()] CLASS-> {moreBrowseActions} function: clickResult()\\n')\n",
    "                print(type(error), str(error))\n",
    "                return False\n",
    "\n",
    "        def backToResults(self):\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('//button[@class=\"section-back-to-list-button blue-link noprint\"]').click()\n",
    "                return True\n",
    "            except Exception as error:\n",
    "                if 'NoSuchElementException' in str(type(error)): return False\n",
    "                \n",
    "                print('ERROR IN [socialMediaScrapper()] CLASS-> {moreBrowseActions} function: backToResults()\\n')\n",
    "                print(type(error), str(error))\n",
    "                return False\n",
    "\n",
    "        def dataFromClickedResult(self, position):\n",
    "            htmlPage = bs4.BeautifulSoup(self.driver.page_source, features='html.parser')\n",
    "\n",
    "            fone, link, address = None, None, None\n",
    "            for r in htmlPage.find_all('div',{'class':'ugiz4pqJLAG__root ugiz4pqJLAG__one-line-text ugiz4pqJLAG__dense ugiz4pqJLAG__metadata-shown-on-hover-only ugiz4pqJLAG__clickable'}):\n",
    "                if r.find('img').get('src') == '//www.gstatic.com/images/icons/material/system_gm/1x/place_gm_blue_24dp.png': address = r.text \n",
    "                if r.find('img').get('src') == '//www.gstatic.com/images/icons/material/system_gm/1x/public_gm_blue_24dp.png': link = r.text\n",
    "                if r.find('img').get('src') == '//www.gstatic.com/images/icons/material/system_gm/1x/phone_gm_blue_24dp.png': fone = r.text\n",
    "\n",
    "            name = htmlPage.find('h1',{'class':'section-hero-header-title-title GLOBAL__gm2-headline-5'})\n",
    "            if name != None and name.find('span') != None: name = name.find('span').text\n",
    "            details = htmlPage.find('button',{'jsaction':'pane.rating.category'})\n",
    "            if details != None: details = details.text\n",
    "            classification = htmlPage.find('span',{'class':'section-star-display'})\n",
    "            if classification != None: classification = classification.text\n",
    "\n",
    "            return {'classification': classification, 'position': position, 'name': name, 'fone': fone, 'address': address, 'link': link, 'details': details}\n",
    "    \n",
    "    def findSocialMediaAccounts(self, data_business, print_process=True):\n",
    "        ''' recebe uma lista ou dataframe e procura pelas redes sociais em seus sites'''\n",
    "        business_df = data_business\n",
    "\n",
    "        assert str(type(business_df)) == \"<class 'pandas.core.frame.DataFrame'>\", 'o input deve ser um pandas.dataframe'\n",
    "\n",
    "        for row, link in business_df[business_df['link'].isnull() == False]['link'].T.iteritems():\n",
    "            try:\n",
    "                req = requests.get(link)\n",
    "                if req.status_code == 200:\n",
    "                    htmlPage = bs4.BeautifulSoup(req.content, features='html.parser', from_encoding=\"iso-8859-1\")\n",
    "\n",
    "                    business_df.loc[row, 'has_instagram'] = True if str(req.content).find('instagram') != -1 else False\n",
    "                    business_df.loc[row, 'has_facebook'] = True if str(req.content).find('facebook') != -1 else False\n",
    "\n",
    "                    for link in htmlPage.find_all('a'):\n",
    "                        if link.get('href') != None and 'facebook' in link.get('href'):\n",
    "                            business_df.loc[row, 'facebook_link'] = link.get('href')\n",
    "                        elif link.get('href') != None and 'instagram' in link.get('href'):\n",
    "                            business_df.loc[row, 'instagram_link'] = link.get('href')\n",
    "\n",
    "                    if print_process == True and row % 100 == 0:\n",
    "                        print('{} processed'.format(row))\n",
    "                else:\n",
    "                    business_df.loc[row, 'link_problem'] = True \n",
    "            except Exception as error:\n",
    "                business_df.loc[row, 'link_problem'] = True\n",
    "        return business_df\n",
    "    \n",
    "    def getInstagramData(self, data_business, print_process=True, clean=True):\n",
    "        ''' Ira pegar os dados gerais das contas de Instagram encontradas '''\n",
    "        data = data_business\n",
    "\n",
    "        assert str(type(data)) == \"<class 'pandas.core.frame.DataFrame'>\", 'o input deve ser um pandas.dataframe'    \n",
    "        # verifica se ha navegador aberto, se nao houver ira abrir\n",
    "        try:\n",
    "            self.driver.current_url\n",
    "        except Exception as error: \n",
    "            if 'chrome not reachable' or 'HTTPConnectionPool' in str(error):\n",
    "                self.driver_()\n",
    "\n",
    "        for row, link in data[data['instagram_link'].isnull() == False]['instagram_link'].T.iteritems():\n",
    "            first_w = data.loc[row]['instagram_link'].find('w')\n",
    "            content = data.loc[row]['instagram_link']\n",
    "            data.loc[row]['instagram_link'] = 'https://' + content[first_w:]\n",
    "            \n",
    "            try:\n",
    "                self.driver.get(link)\n",
    "                htmlPage = bs4.BeautifulSoup(self.driver.page_source, features='html.parser', from_encoding=\"iso-8859-1\")\n",
    "\n",
    "                # PEGA OS DADOS NUMERICOS DA PAGINA\n",
    "                numbers = htmlPage.find_all('a', {'class':'-nal3'})\n",
    "                if numbers != None:\n",
    "                    data.loc[row, 'instagram_posts'] = numbers[0].text\n",
    "                    data.loc[row, 'instagram_followers'] = numbers[1].text\n",
    "                    data.loc[row, 'instagram_following'] = numbers[2].text\n",
    "\n",
    "                #PEGA OS DADOS DE TEXTO DA PAGINA\n",
    "                data_text = htmlPage.find('div', {'class':'-vDIg'})\n",
    "                page_name = data_text.find('h1', {'class':'rhpdm'})\n",
    "                if page_name != None: data.loc[row, 'instagram_page_name'] = page_name.text\n",
    "                bio_text = data_text.find('span')   \n",
    "                if bio_text != None: data.loc[row, 'instagram_bio_text'] = bio_text.text\n",
    "                link = data_text.find('a',{'class':'yLUwa'})\n",
    "                if link != None: data.loc[row, 'instagram_bio_link'] = link.get('href')\n",
    "                username = htmlPage.find('h2', {'class':'_7UhW9'})\n",
    "                if username != None: data.loc[row, 'instagram_username'] = username.text\n",
    "\n",
    "                if print_process == True: print('getting Instagram Data, {} processed, last username saved: {}'.format(row, username.text))\n",
    "                time.sleep(1)\n",
    "            except Exception as error:\n",
    "                if 'IndexError' in str(type(error)):\n",
    "                    unavilable = htmlPage.find('div',{'class':'_07DZ3'})\n",
    "                    data.loc[row, 'instagram_link_problem'] = True if unavilable != None and \"Sorry, this page isn't available.\" in unavilable.text else None\n",
    "                    continue \n",
    "                else:\n",
    "                    data.loc[row, 'instagram_link_problem'] = '404'\n",
    "        \n",
    "        if clean == False:\n",
    "            return data\n",
    "        else:\n",
    "            clean = ProcessData()\n",
    "            return clean.cleanInstagramData(data)\n",
    "        \n",
    "    def getFacebookData(self, data_business, print_process=True, clean=True):\n",
    "        ''' Ira pegar os dados gerais das contas de Facebook encontradas '''\n",
    "        data = data_business\n",
    "\n",
    "        assert str(type(data)) == \"<class 'pandas.core.frame.DataFrame'>\", 'o input deve ser um pandas.dataframe'    \n",
    "        # verifica se ha navegador aberto, se nao houver ira abrir\n",
    "        try:\n",
    "            self.driver.current_url\n",
    "        except Exception as error: \n",
    "            if 'chrome not reachable' or 'HTTPConnectionPool' in str(error):\n",
    "                self.driver_()\n",
    "        \n",
    "        for row, link in data[data['facebook_link'].isnull() == False]['facebook_link'].T.iteritems():\n",
    "            try:\n",
    "                self.driver.get(link)\n",
    "                htmlPage = bs4.BeautifulSoup(self.driver.page_source, features='html.parser')\n",
    "\n",
    "                facebook_page_name = htmlPage.find('span', {'class':'_33vv'})\n",
    "                if facebook_page_name != None: data.loc[row, 'facebook_page_name'] = facebook_page_name.text\n",
    "\n",
    "                facebook_page_user = htmlPage.find('a', {'class':'_2wmb'})\n",
    "                if facebook_page_user != None: data.loc[row, 'facebook_page_user'] = facebook_page_user.text\n",
    "\n",
    "                page_data = htmlPage.find('div', {'class':'_4-u2 _6590 _3xaf _4-u8'})\n",
    "                \n",
    "                if page_data != None:\n",
    "                    saved = []\n",
    "                    for div in page_data.find_all('div'):\n",
    "                        if div.text not in saved:\n",
    "                            if 'follow' in div.text or 'seguindo ' in div.text:\n",
    "                                data.loc[row, 'facebook_followers'] = div.text\n",
    "                            elif 'like' in div.text or 'curtiram' in div.text:\n",
    "                                data.loc[row, 'facebook_likes'] = div.text\n",
    "                            elif 'check' in div.text:\n",
    "                                data.loc[row, 'check-ins'] = div.text\n",
    "                else:\n",
    "                    data.loc[row, 'facebook_link_problem'] = True\n",
    "\n",
    "                about_content = htmlPage.find('div', {'class':'_4-u2 _u9q _3xaf _4-u8'})\n",
    "                data.loc[row, 'about_content'] = str(about_content)\n",
    "\n",
    "                time.sleep(1)\n",
    "                if print_process == True: print('getting Facebook Data, {} processed'.format(row))\n",
    "            except Exception as error:\n",
    "                print(type(error), print(error))\n",
    "                data.loc[row, 'facebook_link_problem'] = True\n",
    "\n",
    "        if clean == False:\n",
    "            return data\n",
    "        else:\n",
    "            clean = ProcessData()\n",
    "            return clean.cleanFacebookData(data)\n",
    "        \n",
    "    def getAdsData(self, data_business, print_process=True, clean=True):\n",
    "        ''' Ira pegar os dados de anuncios encontrados '''\n",
    "        self.dataAds = data_business\n",
    "        \n",
    "        assert str(type(data_business)) == \"<class 'pandas.core.frame.DataFrame'>\", 'o input deve ser um pandas.dataframe'    \n",
    "        # verifica se ha navegador aberto, se nao houver ira abrir\n",
    "        try:\n",
    "            sp.driver.current_url\n",
    "        except Exception as error: \n",
    "            if 'chrome not reachable' or 'HTTPConnectionPool' in str(error):\n",
    "                sp.driver_()\n",
    "\n",
    "        sp.driver.get('https://pt-br.facebook.com/ads/library')\n",
    "        time.sleep(1)\n",
    "\n",
    "        for row, content in self.dataAds.loc[(self.dataAds['facebook_page_name'].isnull() == False)][['facebook_page_name', 'facebook_page_user']].T.iteritems():\n",
    "            clicked = self.searchPageName(content['facebook_page_name'], content['facebook_page_user'])\n",
    "            \n",
    "            if clicked == False: \n",
    "                self.dataAds.loc[row, 'ads_page_problem'] = '404' #rodou todos os resultados e nao encontrou a pagina\n",
    "            elif clicked == True or clicked == 'By_page_name':\n",
    "                if not(self.getDataAdsPage(row)): \n",
    "                    self.dataAds.loc[row, 'ads_page_problem'] = True #por alguma razao nao encontrou os dados\n",
    "                elif clicked == 'By_page_name':\n",
    "                    self.dataAds.loc[row, 'ads_page_problem'] = 'By_page_name'\n",
    "\n",
    "                time.sleep(1)\n",
    "                print('{} pages processed'.format(row))\n",
    "        \n",
    "        if clean == False:\n",
    "            return self.dataAds\n",
    "        else:\n",
    "            clean = ProcessData()\n",
    "            return clean.cleanAdsData(self.dataAds)\n",
    "\n",
    "    def clickInPageResultList(self, facebook_page_info, by_page_name=False):\n",
    "        '''\n",
    "            procura a pagina na lista de resultados e se algum resultado na lista tiver o mesmo @usuario ira clicar\n",
    "        '''\n",
    "\n",
    "        div_to_find = '_8t5z' if by_page_name == False else '_7h1e'\n",
    "        results = sp.driver.find_elements_by_class_name(div_to_find)\n",
    "\n",
    "        if results != None:\n",
    "            for result in results:\n",
    "                content_to_verify = result.text[:result.text.find(' ')] if by_page_name == False else result.text\n",
    "                # se nao for pelo nome da pagina, ira pegar o nome de usuario que esta no inicio do texto\n",
    "\n",
    "                if facebook_page_info == content_to_verify:\n",
    "                    result.click()\n",
    "                    time.sleep(3)\n",
    "                    return True\n",
    "            return False\n",
    "        else:\n",
    "            return 'Not Found'\n",
    "\n",
    "    def searchPageName(self, facebook_page_name, facebook_page_user):\n",
    "        '''\n",
    "            Recebe uma pagina e seu nome_de_usuario e pesquisa na biblioteca de anuncio\n",
    "        '''\n",
    "        try:\n",
    "            search_box = sp.driver.find_element_by_class_name('_7hgq')\n",
    "            search_box.click()\n",
    "\n",
    "            for char in search_box.get_attribute('value'):\n",
    "                search_box.send_keys(Keys.BACKSPACE)\n",
    "                #apaga qualquer conteudo escrito na barra de pesquisa\n",
    "\n",
    "            search_box.send_keys(facebook_page_name)\n",
    "            time.sleep(2)\n",
    "\n",
    "            clicked = self.clickInPageResultList(facebook_page_user)\n",
    "\n",
    "            # SE NAO ENCONTROU A PAGINA NA LISTA IRA VERIFICAR SE HA OPCAO VER MAIS E SE ESTA MAIS ABAIXO NOS RESULTADOS\n",
    "            if clicked == False:\n",
    "                try:\n",
    "                    more_results = more_results = sp.driver.find_element_by_class_name('_7h65')\n",
    "                    more_results.click()\n",
    "                    time.sleep(1)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                if self.clickInPageResultList(facebook_page_user):\n",
    "                    return True\n",
    "                else:\n",
    "                    # se ainda assim nao encontrar a pagina ira tentar pelo nome da pagina\n",
    "                    if self.clickInPageResultList(facebook_page_name, by_page_name=True):\n",
    "                        return 'By_page_name'\n",
    "                    else:\n",
    "                        False\n",
    "            else:\n",
    "                return True\n",
    "        except Exception as error:\n",
    "            print('error in: [searchPageName]: \\n')\n",
    "            print(type(error), error)\n",
    "            return 'Error'\n",
    "\n",
    "    def getDataAdsPage(self, dataframe_row):\n",
    "        htmlPage = bs4.BeautifulSoup(sp.driver.page_source, features='html.parser')\n",
    "        self.dataAds.loc[dataframe_row, 'library_ads_url'] = sp.driver.current_url\n",
    "        time.sleep(1)\n",
    "\n",
    "        active_ads = htmlPage.find('div',{'class':'_7gn2'})\n",
    "        if active_ads != None: self.dataAds.loc[dataframe_row, 'active_ads'] = active_ads.text\n",
    "\n",
    "        page_data = htmlPage.find('div',{'class':'_3-8- _3qn7 _61-0 _2fyh _3qnf'})\n",
    "        if page_data != None:\n",
    "            for row_in_list in page_data.find_all('div'):\n",
    "                # percorre as linhas ate encontrar o icone de pagina criada ira pegar o conteudo\n",
    "                if row_in_list.find('i', {'class': 'img sp_9Pca48nsujv sx_50d5dd'}) != None: \n",
    "                    created_in = row_in_list.find('span',{'class':'_3-99'})\n",
    "                    if created_in != None: self.dataAds.loc[dataframe_row, 'created_in'] = created_in.text\n",
    "                    return True\n",
    "                else:\n",
    "                    self.dataAds.loc[dataframe_row, 'created_in'] = '404' #por alguma razao nao encontrou os dados entao ira retornar False\n",
    "        else:\n",
    "            self.dataAds.loc[dataframe_row, 'created_in'] = '404' #por alguma razao nao encontrou os dados entao ira retornar False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessData():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def googleSearchResults(self, results_list):\n",
    "        ''' * reomocao de duplicatos pelo endereco '''\n",
    "        \n",
    "        self.data = [] #sera o dataframe com os dados\n",
    "        \n",
    "        #recebe a lista de resultados do google e processa os dados\n",
    "        for count, r in enumerate(results_list):\n",
    "            name = r.find('h3', {'class':'section-result-title'})\n",
    "            if name != None: name = name.text\n",
    "            address = r.find('span', {'class':'section-result-location'})\n",
    "            if address != None: address = address.text\n",
    "            details = r.find('span', {'class':'section-result-details'})\n",
    "            if details != None: details = details.text\n",
    "            fone = r.find('span', {'class':'section-result-info section-result-phone-number'})\n",
    "            if fone != None: fone = fone.text\n",
    "            link = r.find('a')\n",
    "            if link != None: link = link.get('href')\n",
    "            classification = r.find('span', {'class':'cards-rating-score'})\n",
    "            if classification != None: classification = classification.text\n",
    "\n",
    "            data_result = {'classification': classification, 'position': count+1, 'name': name, 'fone': fone, 'address': address, 'link': link, 'details': details}\n",
    "            self.data.append(data_result)\n",
    "    \n",
    "        self.data = pd.DataFrame(self.data)\n",
    "        self.data.drop_duplicates(['address']) \n",
    "        self.data.reset_index(drop=True, inplace=True)\n",
    "        return self.data\n",
    "    \n",
    "    def cleanInstagramData(self, business_df):\n",
    "        ''' Limpa os dados coletados do Instagram '''\n",
    "        data_instagram_page = business_df\n",
    "        assert str(type(data_instagram_page)) == \"<class 'pandas.core.frame.DataFrame'>\", 'o input deve ser um pandas.dataframe'    \n",
    "\n",
    "        for row, content in data_instagram_page[data_instagram_page.instagram_followers.isnull() == False].T.iteritems():\n",
    "            data_instagram_page.loc[row, 'instagram_posts'] = self.processQntOnString(content['instagram_posts'][:content['instagram_posts'].find(' ')].replace(',', ''))\n",
    "            data_instagram_page.loc[row, 'instagram_followers'] = self.processQntOnString(content['instagram_followers'][:content['instagram_followers'].find(' ')].replace(',', '.'))\n",
    "            data_instagram_page.loc[row, 'instagram_following'] = self.processQntOnString(content['instagram_following'][:content['instagram_following'].find(' ')].replace(',', '.'))\n",
    "        return data_instagram_page\n",
    "\n",
    "    def processQntOnString(self, qnt_string):\n",
    "        '''\n",
    "            Nas quantidade podera contar 'k' ou 'm' para mil ou milhoes\n",
    "        '''\n",
    "        try:\n",
    "            key = ''.join(filter(str.isalpha, qnt_string))\n",
    "            total_chars = '0'*6 if key == 'm' else '0'*3 if key == 'k' else '0'*3 if key == 'mil' else '0'*6 if key == 'mi' else None  \n",
    "\n",
    "            if total_chars != None and key in qnt_string and '.' in qnt_string:\n",
    "                #verifica quantos numeros apos o ponto flutuante e retira essa quantidade de zeros\n",
    "                total_chars = total_chars[len(qnt_string[qnt_string.find('.')+1:qnt_string.find('m')]):]\n",
    "                qnt_string = qnt_string.replace(key, total_chars).replace('.','')\n",
    "                return int(qnt_string)\n",
    "            elif total_chars != None and key in qnt_string:\n",
    "                qnt_string = qnt_string.replace(key, total_chars)\n",
    "                return int(qnt_string)\n",
    "            else:\n",
    "                return int(qnt_string.replace('.', ''))\n",
    "        except:\n",
    "            return 'Error in value: {}'.format(qnt_string)\n",
    "        \n",
    "    def cleanFacebookData(self, data_business):\n",
    "        data_facacebook_page = data_business\n",
    "        for row, content in data_facacebook_page[data_facacebook_page.facebook_page_name.isnull() == False].T.iteritems():\n",
    "            if str(content['facebook_likes']) != 'nan': data_facacebook_page.loc[row, 'facebook_likes'] = int(content['facebook_likes'][:content['facebook_likes'].find(' ')].replace(',', '').replace('.', ''))\n",
    "            if str(content['facebook_followers']) != 'nan': data_facacebook_page.loc[row, 'facebook_followers'] = int(content['facebook_followers'][:content['facebook_followers'].find(' ')].replace(',', '').replace('.', ''))\n",
    "            if str(content['check-ins']) != 'nan': data_facacebook_page.loc[row, 'check-ins'] = int(content['check-ins'][:content['check-ins'].find(' ')].replace(',', '').replace('.', ''))\n",
    "        \n",
    "        return data_facacebook_page\n",
    "    \n",
    "    def cleanAdsData(self, data_business):\n",
    "        ads_data = data_business\n",
    "        \n",
    "        assert str(type(ads_data)) == \"<class 'pandas.core.frame.DataFrame'>\", 'o input deve ser um pandas.dataframe'    \n",
    "        \n",
    "        months = {'Jan': '01', 'Fev': '02', 'Mar': '03', 'Abr': '04', 'Maio': '05', 'Mai': '05', 'Jun': '06', \n",
    "                 'Jul': '07', 'Ago': '08', 'Set': '09', 'Out': '10', 'Nov': '11', 'Dez': '12'}\n",
    "        \n",
    "        for row, content in ads_data.loc[(ads_data.active_ads.isnull() == False)][['active_ads', 'created_in']].T.iteritems():\n",
    "            try:\n",
    "                ads_data.loc[row, 'active_ads'] = int(''.join(filter(str.isdigit, content['active_ads'])))\n",
    "            except TypeError: \n",
    "                pass\n",
    "            try:\n",
    "                data_ = content['created_in'].replace(' de ', '/')\n",
    "                month_str = data_.split('/')[1]\n",
    "                print(month_str)\n",
    "                ads_data.loc[row, 'created_in'] = pd.to_datetime(data_.replace(month_str, months[month_str]))\n",
    "\n",
    "            except Exception as error:\n",
    "                print('ERROR IN ROW ({}) [socialMediaScrapper()] function: cleanAdsData()\\n'.format(row))\n",
    "                print(type(error), str(error))\n",
    "                \n",
    "        return data_business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:211: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "c:\\users\\yan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\bs4\\__init__.py:177: UserWarning:\n",
      "\n",
      "You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting Instagram Data, 0 processed, last username saved: clinica.curitiba\n",
      "getting Instagram Data, 1 processed, last username saved: chcufpr\n",
      "getting Instagram Data, 2 processed, last username saved: chcufpr\n",
      "getting Instagram Data, 5 processed, last username saved: clinicameitan\n",
      "getting Instagram Data, 6 processed, last username saved: paranaclinicas\n",
      "getting Instagram Data, 11 processed, last username saved: otorrinoclinica\n",
      "getting Instagram Data, 17 processed, last username saved: policlinica_sitio_cercado_ofc\n",
      "getting Instagram Data, 28 processed, last username saved: cendicor_cendicorbaby\n",
      "getting Instagram Data, 30 processed, last username saved: ortopediasete\n",
      "getting Instagram Data, 33 processed, last username saved: neoderme\n",
      "getting Instagram Data, 34 processed, last username saved: clinicalosangelescuritiba\n",
      "getting Instagram Data, 38 processed, last username saved: oftalmocuritiba\n",
      "getting Instagram Data, 40 processed, last username saved: clinica_cardiocare\n",
      "getting Instagram Data, 41 processed, last username saved: ortopediahauer\n",
      "getting Instagram Data, 43 processed, last username saved: fundacaoprorenal\n",
      "getting Instagram Data, 56 processed, last username saved: maxiclin\n",
      "getting Instagram Data, 59 processed, last username saved: clinicadefraturastorres\n",
      "getting Instagram Data, 74 processed, last username saved: hospitalportoseguro\n",
      "getting Instagram Data, 87 processed, last username saved: ortopediasete\n",
      "getting Instagram Data, 89 processed, last username saved: clinicasercuritiba\n",
      "getting Instagram Data, 90 processed, last username saved: clinica.cedip\n",
      "getting Instagram Data, 91 processed, last username saved: one.curitiba\n",
      "getting Instagram Data, 95 processed, last username saved: peleclin\n",
      "getting Instagram Data, 96 processed, last username saved: clinicacepelle\n",
      "getting Instagram Data, 97 processed, last username saved: clinicaprevenirbrasil\n",
      "getting Instagram Data, 98 processed, last username saved: chcufpr\n",
      "getting Instagram Data, 100 processed, last username saved: prodentalcuritiba\n",
      "getting Instagram Data, 106 processed, last username saved: nutri_marimaciel\n",
      "getting Instagram Data, 122 processed, last username saved: chcufpr\n",
      "getting Instagram Data, 123 processed, last username saved: dracarolineobrali\n",
      "getting Instagram Data, 131 processed, last username saved: paranaclinicas\n",
      "getting Instagram Data, 135 processed, last username saved: chcufpr\n",
      "getting Instagram Data, 139 processed, last username saved: clinicaconcebercuritiba\n",
      "getting Instagram Data, 150 processed, last username saved: odontocompany\n",
      "getting Instagram Data, 153 processed, last username saved: clinica.curitiba\n",
      "getting Instagram Data, 154 processed, last username saved: clinicaintento\n",
      "getting Instagram Data, 157 processed, last username saved: clinica.dapi\n",
      "getting Instagram Data, 160 processed, last username saved: clinica_ident\n",
      "getting Instagram Data, 161 processed, last username saved: nossodentistacuritiba_\n",
      "getting Instagram Data, 163 processed, last username saved: clinicabellage\n",
      "getting Instagram Data, 164 processed, last username saved: oftalmoplastica\n",
      "getting Instagram Data, 166 processed, last username saved: clinica.dapi\n",
      "getting Instagram Data, 168 processed, last username saved: amorsaudebrasil\n",
      "getting Instagram Data, 170 processed, last username saved: acruzeirodosul\n",
      "getting Instagram Data, 173 processed, last username saved: clinica.dapi\n",
      "getting Instagram Data, 176 processed, last username saved: caetano_marchesini\n",
      "getting Instagram Data, 181 processed, last username saved: clinica_ident\n",
      "getting Instagram Data, 182 processed, last username saved: nossodentistacuritiba_\n",
      "getting Instagram Data, 184 processed, last username saved: clinicabellage\n",
      "getting Instagram Data, 185 processed, last username saved: oftalmoplastica\n",
      "getting Instagram Data, 187 processed, last username saved: clinica.dapi\n",
      "getting Instagram Data, 189 processed, last username saved: amorsaudebrasil\n",
      "getting Instagram Data, 191 processed, last username saved: acruzeirodosul\n",
      "getting Instagram Data, 194 processed, last username saved: clinica.dapi\n",
      "getting Instagram Data, 197 processed, last username saved: rdicuritiba\n",
      "getting Instagram Data, 200 processed, last username saved: wavemedicinafetal\n",
      "getting Instagram Data, 204 processed, last username saved: odontocompany\n",
      "getting Instagram Data, 209 processed, last username saved: amorsaudebrasil\n",
      "getting Instagram Data, 210 processed, last username saved: boa_pisada\n",
      "getting Instagram Data, 219 processed, last username saved: clinica.cedip\n",
      "getting Instagram Data, 224 processed, last username saved: institutodeoncologiapr\n",
      "getting Instagram Data, 227 processed, last username saved: ijo.med\n",
      "getting Instagram Data, 232 processed, last username saved: tellestransplantecapilar\n",
      "getting Instagram Data, 233 processed, last username saved: institutodeoncologiapr\n",
      "getting Instagram Data, 234 processed, last username saved: maxiclin\n",
      "getting Instagram Data, 235 processed, last username saved: equilibrio_e_bem_estar_cwb\n",
      "getting Instagram Data, 236 processed, last username saved: faicalodontologia\n",
      "getting Instagram Data, 245 processed, last username saved: imunizzare\n",
      "getting Instagram Data, 257 processed, last username saved: hospitalbarigui\n",
      "getting Instagram Data, 260 processed, last username saved: perfecttaodonto\n",
      "getting Instagram Data, 264 processed, last username saved: indic.diagnosticos\n",
      "getting Instagram Data, 265 processed, last username saved: anaclinsjp\n",
      "getting Instagram Data, 269 processed, last username saved: paranaclinicas\n",
      "getting Instagram Data, 270 processed, last username saved: tipclinica\n",
      "getting Instagram Data, 272 processed, last username saved: hospitalportoseguro\n",
      "getting Instagram Data, 273 processed, last username saved: dasa.oficial\n",
      "getting Instagram Data, 279 processed, last username saved: oraluniccuritiba\n",
      "getting Instagram Data, 281 processed, last username saved: ndnucleodiagnostico\n",
      "getting Instagram Data, 290 processed, last username saved: immef\n",
      "getting Instagram Data, 291 processed, last username saved: unibrasil\n",
      "getting Instagram Data, 294 processed, last username saved: geneseclinica\n",
      "getting Instagram Data, 297 processed, last username saved: dentaluni\n",
      "getting Instagram Data, 299 processed, last username saved: carmocentromedico\n",
      "getting Instagram Data, 300 processed, last username saved: oftalmocuritiba\n",
      "getting Instagram Data, 301 processed, last username saved: fetalmedcuritiba\n",
      "getting Instagram Data, 304 processed, last username saved: clinica.dapi\n",
      "getting Instagram Data, 306 processed, last username saved: uroclinicacuritiba\n",
      "getting Instagram Data, 307 processed, last username saved: curitiba_pmc\n",
      "getting Instagram Data, 309 processed, last username saved: clinicasajustar\n",
      "getting Instagram Data, 310 processed, last username saved: magrassoficial\n",
      "getting Instagram Data, 312 processed, last username saved: cendicor_cendicorbaby\n",
      "getting Instagram Data, 314 processed, last username saved: paranaclinicas\n",
      "getting Instagram Data, 320 processed, last username saved: curitiba_pmc\n",
      "getting Instagram Data, 321 processed, last username saved: fetalmedcuritiba\n",
      "getting Instagram Data, 324 processed, last username saved: clinica.dapi\n",
      "getting Instagram Data, 326 processed, last username saved: uroclinicacuritiba\n",
      "getting Instagram Data, 327 processed, last username saved: curitiba_pmc\n",
      "getting Instagram Data, 329 processed, last username saved: clinicasajustar\n",
      "getting Instagram Data, 330 processed, last username saved: magrassoficial\n",
      "getting Instagram Data, 332 processed, last username saved: cendicor_cendicorbaby\n",
      "getting Instagram Data, 334 processed, last username saved: paranaclinicas\n",
      "getting Instagram Data, 347 processed, last username saved: clinicaluxcuritiba\n",
      "getting Instagram Data, 348 processed, last username saved: laboratorio.fa\n",
      "getting Instagram Data, 349 processed, last username saved: laboratorio.fa\n",
      "getting Instagram Data, 352 processed, last username saved: laboratorio.fa\n",
      "getting Instagram Data, 355 processed, last username saved: fleury\n",
      "getting Instagram Data, 359 processed, last username saved: odontocompany\n",
      "getting Instagram Data, 367 processed, last username saved: clinicaluxcuritiba\n",
      "getting Instagram Data, 368 processed, last username saved: laboratorio.fa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting Instagram Data, 369 processed, last username saved: laboratorio.fa\n",
      "getting Instagram Data, 372 processed, last username saved: laboratorio.fa\n",
      "getting Instagram Data, 375 processed, last username saved: fleury\n",
      "getting Instagram Data, 382 processed, last username saved: hnsgcuritiba\n",
      "getting Instagram Data, 386 processed, last username saved: unimedcuritibaoficial\n",
      "getting Instagram Data, 389 processed, last username saved: magrassoficial\n",
      "getting Instagram Data, 391 processed, last username saved: odontocompany\n",
      "getting Instagram Data, 393 processed, last username saved: hnsgcuritiba\n",
      "getting Instagram Data, 394 processed, last username saved: magrassoficial\n",
      "getting Instagram Data, 396 processed, last username saved: cvrveterinaria\n",
      "getting Instagram Data, 397 processed, last username saved: magrassoficial\n"
     ]
    }
   ],
   "source": [
    "# sp = socialMediaScrapper()\n",
    "# saude_curitiba = sp.googleSearch()\n",
    "# saude_curitiba = sp.findSocialMediaAccounts(saude_curitiba)\n",
    "saude_curitiba = sp.getInstagramData(saude_curitiba)\n",
    "# saude_curitiba = sp.getFacebookData(saude_curitiba)\n",
    "# saude_curitiba = sp.getAdsData(saude_curitiba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>classification</th>\n",
       "      <th>details</th>\n",
       "      <th>fone</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>position</th>\n",
       "      <th>has_instagram</th>\n",
       "      <th>has_facebook</th>\n",
       "      <th>facebook_link</th>\n",
       "      <th>instagram_link</th>\n",
       "      <th>link_problem</th>\n",
       "      <th>instagram_posts</th>\n",
       "      <th>instagram_followers</th>\n",
       "      <th>instagram_following</th>\n",
       "      <th>instagram_page_name</th>\n",
       "      <th>instagram_bio_text</th>\n",
       "      <th>instagram_bio_link</th>\n",
       "      <th>instagram_username</th>\n",
       "      <th>instagram_link_problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alameda Júlia da Costa, 1447</td>\n",
       "      <td>4,7</td>\n",
       "      <td>Centro médico</td>\n",
       "      <td>(41) 3240-2900 ·</td>\n",
       "      <td>http://curitiba.clinicaadventista.org.br/</td>\n",
       "      <td>Clínica Adventista de Curitiba</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.facebook.com/clinica.curitiba</td>\n",
       "      <td>https://www.instagram.com/clinica.curitiba/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143</td>\n",
       "      <td>589</td>\n",
       "      <td>828</td>\n",
       "      <td>Clínica Adventista de Curitiba</td>\n",
       "      <td>👨🏻‍⚕️ Consultas, exames e procedimentos⭐ Mais ...</td>\n",
       "      <td>https://l.instagram.com/?u=http%3A%2F%2Fcuriti...</td>\n",
       "      <td>clinica.curitiba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R. Pasteur, 26</td>\n",
       "      <td>3,9</td>\n",
       "      <td>Clínica oftalmológica</td>\n",
       "      <td>(41) 3523-0082 ·</td>\n",
       "      <td>http://www.hc.ufpr.br/</td>\n",
       "      <td>UFPR - Centro de Visão do Hospital de Clínicas</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.facebook.com/chcufpr</td>\n",
       "      <td>https://www.instagram.com/chcufpr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265</td>\n",
       "      <td>5489</td>\n",
       "      <td>8</td>\n",
       "      <td>Complexo HC UFPR</td>\n",
       "      <td>Perfil Oficial do Complexo Hospital de Clínica...</td>\n",
       "      <td>https://l.instagram.com/?u=http%3A%2F%2Ffacebo...</td>\n",
       "      <td>chcufpr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R. Gen. Carneiro, 181</td>\n",
       "      <td>4,7</td>\n",
       "      <td>Clínica da saúde da mulher</td>\n",
       "      <td>(41) 3360-1800 ·</td>\n",
       "      <td>http://www.hc.ufpr.br/</td>\n",
       "      <td>Maternidade Do Hospital De Clínicas</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.facebook.com/chcufpr</td>\n",
       "      <td>https://www.instagram.com/chcufpr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265</td>\n",
       "      <td>5489</td>\n",
       "      <td>8</td>\n",
       "      <td>Complexo HC UFPR</td>\n",
       "      <td>Perfil Oficial do Complexo Hospital de Clínica...</td>\n",
       "      <td>https://l.instagram.com/?u=http%3A%2F%2Ffacebo...</td>\n",
       "      <td>chcufpr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R. Dr. Raul Carneiro Filho, 328</td>\n",
       "      <td>4,9</td>\n",
       "      <td>Policlínica</td>\n",
       "      <td>(41) 3333-3322 ·</td>\n",
       "      <td>http://www.clinicamedicamaisvida.com.br/</td>\n",
       "      <td>Clínica Médica Mais Vida</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Av. Luiz Xavier, 68</td>\n",
       "      <td>3,2</td>\n",
       "      <td>Clínica oftalmológica</td>\n",
       "      <td>(41) 3322-9537 ·</td>\n",
       "      <td>http://www.clinicatijucas.com.br/</td>\n",
       "      <td>CLÍNICA TIJUCAS Clínica de Oftalmologia e Gine...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           address classification                     details  \\\n",
       "0     Alameda Júlia da Costa, 1447            4,7               Centro médico   \n",
       "1                   R. Pasteur, 26            3,9       Clínica oftalmológica   \n",
       "2            R. Gen. Carneiro, 181            4,7  Clínica da saúde da mulher   \n",
       "3  R. Dr. Raul Carneiro Filho, 328            4,9                 Policlínica   \n",
       "4              Av. Luiz Xavier, 68            3,2       Clínica oftalmológica   \n",
       "\n",
       "                 fone                                       link  \\\n",
       "0   (41) 3240-2900 ·   http://curitiba.clinicaadventista.org.br/   \n",
       "1   (41) 3523-0082 ·                      http://www.hc.ufpr.br/   \n",
       "2   (41) 3360-1800 ·                      http://www.hc.ufpr.br/   \n",
       "3   (41) 3333-3322 ·    http://www.clinicamedicamaisvida.com.br/   \n",
       "4   (41) 3322-9537 ·           http://www.clinicatijucas.com.br/   \n",
       "\n",
       "                                                name  position has_instagram  \\\n",
       "0                     Clínica Adventista de Curitiba         1          True   \n",
       "1     UFPR - Centro de Visão do Hospital de Clínicas         2          True   \n",
       "2                Maternidade Do Hospital De Clínicas         3          True   \n",
       "3                           Clínica Médica Mais Vida         4         False   \n",
       "4  CLÍNICA TIJUCAS Clínica de Oftalmologia e Gine...         5         False   \n",
       "\n",
       "  has_facebook                              facebook_link  \\\n",
       "0         True  https://www.facebook.com/clinica.curitiba   \n",
       "1         True           https://www.facebook.com/chcufpr   \n",
       "2         True           https://www.facebook.com/chcufpr   \n",
       "3         True                                        NaN   \n",
       "4        False                                        NaN   \n",
       "\n",
       "                                instagram_link link_problem instagram_posts  \\\n",
       "0  https://www.instagram.com/clinica.curitiba/          NaN             143   \n",
       "1            https://www.instagram.com/chcufpr          NaN             265   \n",
       "2            https://www.instagram.com/chcufpr          NaN             265   \n",
       "3                                          NaN          NaN             NaN   \n",
       "4                                          NaN          NaN             NaN   \n",
       "\n",
       "  instagram_followers instagram_following             instagram_page_name  \\\n",
       "0                 589                 828  Clínica Adventista de Curitiba   \n",
       "1                5489                   8                Complexo HC UFPR   \n",
       "2                5489                   8                Complexo HC UFPR   \n",
       "3                 NaN                 NaN                             NaN   \n",
       "4                 NaN                 NaN                             NaN   \n",
       "\n",
       "                                  instagram_bio_text  \\\n",
       "0  👨🏻‍⚕️ Consultas, exames e procedimentos⭐ Mais ...   \n",
       "1  Perfil Oficial do Complexo Hospital de Clínica...   \n",
       "2  Perfil Oficial do Complexo Hospital de Clínica...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                  instagram_bio_link instagram_username  \\\n",
       "0  https://l.instagram.com/?u=http%3A%2F%2Fcuriti...   clinica.curitiba   \n",
       "1  https://l.instagram.com/?u=http%3A%2F%2Ffacebo...            chcufpr   \n",
       "2  https://l.instagram.com/?u=http%3A%2F%2Ffacebo...            chcufpr   \n",
       "3                                                NaN                NaN   \n",
       "4                                                NaN                NaN   \n",
       "\n",
       "   instagram_link_problem  \n",
       "0                     NaN  \n",
       "1                     NaN  \n",
       "2                     NaN  \n",
       "3                     NaN  \n",
       "4                     NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saude_curitiba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saude_curitiba.to_csv('./Saved Data/Curitiba/saude.csv', index=None)\n",
    "\n",
    "with_ads_page = data[data.active_ads.isnull() == False]\n",
    "with_ads_page = with_ads_page.drop(['classification', 'has_instagram','has_facebook', 'link_problem','instagram_link_problem', 'instagram_bio_text','instagram_bio_link', 'facebook_link_problem', 'about_content', 'library_ads_url', 'ads_page_problem'], axis=1)\n",
    "with_ads_page.sort_values(by=['instagram_posts'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "saude_curitiba.to_excel('./Saved Data/Curitiba/saude.xls', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "prints inline:\n",
    "\n",
    " * Incluir print output inline para funcao que esta fazendo request para todos os sites em busca das redes sociais\n",
    " * para os instagrans e facebook que ja foram processados/encontrados\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saude_curitiba = pd.DataFrame(saude_curitiba)\n",
    "# saude_curitiba.reset_index(drop=True, inplace=True)\n",
    "# saude_curitiba.to_csv('./Saved Data/Curitiba/saude.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
