{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import bs4, time, requests\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "import numpy as np\n",
    "\n",
    "import plotly\n",
    "from plotly.offline import plot_mpl\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "plotly.offline.init_notebook_mode(connected=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega todos os resultados do google\n",
    "class socialMediaScrapper():\n",
    "    def __init__(self, has_data=False):\n",
    "        if has_data != True: self.driver_() #inicia o navegador\n",
    "\n",
    "    def __call__(self):\n",
    "        #ao chamar como funcao ira fazer fazer a pesquisa, pegar os dados das redes sociais e tambem de anuncios\n",
    "        print('getting search results...')\n",
    "        self.saude_curitiba = self.googleSearch()\n",
    "        print('findind social media accounts...')\n",
    "        self.saude_curitiba = self.findSocialMediaAccounts(self.saude_curitiba)\n",
    "        print('getting instagram data...')\n",
    "        self.saude_curitiba = self.getInstagramData(self.saude_curitiba)\n",
    "        print('getting facebook data...')\n",
    "        self.saude_curitiba = self.getFacebookData(self.saude_curitiba)\n",
    "        print('getting ads data...')\n",
    "        self.saude_curitiba = self.getAdsData(self.saude_curitiba)\n",
    "        print('all done')\n",
    "        return self.saude_curitiba\n",
    "    \n",
    "    def driver_(self):\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"profile\")\n",
    "        options.add_argument(\"user-data-dir=./Browser/Profile\")\n",
    "        \n",
    "        if \"Windows\" in platform.platform():\n",
    "            executable_path = './Browser/Driver/Win/chromedriver.exe' \n",
    "            print('Platform: Windows')\n",
    "        else:\n",
    "            executable_path = './Browser/Driver/chromedriver'\n",
    "            \n",
    "        self.driver = webdriver.Chrome(executable_path=executable_path, options=options)\n",
    "\n",
    "        \n",
    "        \n",
    "    def nextPage(self):\n",
    "        # Procura o botao para a pr√≥xima p√°gina\n",
    "        htmlPage = bs4.BeautifulSoup(self.driver.page_source, features='html.parser')\n",
    "\n",
    "        button_status = htmlPage.find('button', {'jsaction':'pane.paginationSection.nextPage'})\n",
    "        button_next = htmlPage.find('span', {'class':'n7lv7yjyC35__button-next-icon'})\n",
    "        if button_status != None and button_status.get('disabled') == 'true':\n",
    "            return 'end'\n",
    "        elif button_next != None:\n",
    "            return 'next'\n",
    "\n",
    "    def typeResultList(self):\n",
    "        ''' encontra qual o tipo de resultados que o google devolveu\n",
    "            * ha resultados com o link direto\n",
    "            * ha resultados que precisa de um clique para acessar os dados\n",
    "        '''\n",
    "        htmlPage = bs4.BeautifulSoup(self.driver.page_source, features='html.parser')\n",
    "        route_button = htmlPage.find('div',{'class':'section-result-action-icon-container'})\n",
    "        if route_button != None:\n",
    "            return 'simple'\n",
    "        else:\n",
    "            return 'need click'\n",
    "    \n",
    "    def googleSearch(self, url=None, clean=True):\n",
    "        '''\n",
    "            * pode ser chamado sem url desde que esteja na aba da pesquisa\n",
    "            * clean=True para retornar os dados ja limpes pelo modulo ProcessData\n",
    "        '''\n",
    "        if url == None:\n",
    "            input('Aperte Enter quando j√° estiver na pesquisa que deseja capturar os dados: ')\n",
    "        else:\n",
    "            self.driver.get(url)\n",
    "            time.sleep(2)\n",
    "\n",
    "        # Verifica qual o tipo de resultados\n",
    "        if self.typeResultList() == 'need click':\n",
    "            # importa a outra classe para usar\n",
    "            moreActions = self.moreBrowseActions(self.driver)\n",
    "            simpleScrapp = False\n",
    "        else:\n",
    "            simpleScrapp  = True\n",
    "        \n",
    "        results = []\n",
    "        while True:\n",
    "            try:\n",
    "                htmlPage = bs4.BeautifulSoup(self.driver.page_source, features='html.parser')\n",
    "                if simpleScrapp == True:\n",
    "                    results.extend(htmlPage.find_all('div', {'class':'section-result'}))\n",
    "                else:\n",
    "                    click_error = 0\n",
    "                    for i in range(1, 21):\n",
    "                        if moreActions.clickResult(i) == False: click_error+=1\n",
    "                        if click_error >=2: break\n",
    "                        \n",
    "                        time.sleep(2)\n",
    "                        results.append(moreActions.dataFromClickedResult(i))\n",
    "                        moreActions.backToResults()\n",
    "                        time.sleep(1)\n",
    "                        \n",
    "                        \n",
    "                if self.nextPage() == 'end': \n",
    "                    break\n",
    "                else:\n",
    "                    next_page = self.driver.find_element_by_class_name('n7lv7yjyC35__button-next-icon')\n",
    "                    next_page.click()\n",
    "                    time.sleep(2)\n",
    "            except KeyboardInterrupt: \n",
    "                break\n",
    "            except Exception as error:\n",
    "                if htmlPage.find('div',{'class':'section-no-result noprint'}) != None: \n",
    "                    break\n",
    "                else:\n",
    "                    print('ERROR IN [socialMediaScrapper()] function: googleSearch()\\n')\n",
    "                    print(type(error), str(error))\n",
    "        \n",
    "        if simpleScrapp == False:\n",
    "            results = pd.DataFrame(results)\n",
    "            results.reset_index(drop=True, inplace=True)\n",
    "            return results\n",
    "        elif clean == False:\n",
    "            return list(set(results))\n",
    "        else:\n",
    "            clean = ProcessData()\n",
    "            return clean.googleSearchResults(results)\n",
    "        \n",
    "    class moreBrowseActions():\n",
    "        ''' acoes extras para o navegador caso os resultados nao estejam na lista e precise ser clicado'''\n",
    "        def __init__(self, driver):\n",
    "            self.driver = driver\n",
    "            \n",
    "        def clickResult(self, position):\n",
    "            ''' ira clicar no resultado e extrair os dados'''\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('//div[@data-result-index=' + str(position) + ']').click()\n",
    "                return True\n",
    "            except Exception as error:\n",
    "                if 'NoSuchElementException' in str(type(error)): return False\n",
    "                \n",
    "                print('ERROR IN [socialMediaScrapper()] CLASS-> {moreBrowseActions} function: clickResult()\\n')\n",
    "                print(type(error), str(error))\n",
    "                return False\n",
    "\n",
    "        def backToResults(self):\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('//button[@class=\"section-back-to-list-button blue-link noprint\"]').click()\n",
    "                return True\n",
    "            except Exception as error:\n",
    "                if 'NoSuchElementException' in str(type(error)): return False\n",
    "                \n",
    "                print('ERROR IN [socialMediaScrapper()] CLASS-> {moreBrowseActions} function: backToResults()\\n')\n",
    "                print(type(error), str(error))\n",
    "                return False\n",
    "\n",
    "        def dataFromClickedResult(self, position):\n",
    "            htmlPage = bs4.BeautifulSoup(self.driver.page_source, features='html.parser')\n",
    "\n",
    "            fone, link, address = None, None, None\n",
    "            for r in htmlPage.find_all('div',{'class':'ugiz4pqJLAG__root ugiz4pqJLAG__one-line-text ugiz4pqJLAG__dense ugiz4pqJLAG__metadata-shown-on-hover-only ugiz4pqJLAG__clickable'}):\n",
    "                if r.find('img').get('src') == '//www.gstatic.com/images/icons/material/system_gm/1x/place_gm_blue_24dp.png': address = r.text \n",
    "                if r.find('img').get('src') == '//www.gstatic.com/images/icons/material/system_gm/1x/public_gm_blue_24dp.png': link = r.text\n",
    "                if r.find('img').get('src') == '//www.gstatic.com/images/icons/material/system_gm/1x/phone_gm_blue_24dp.png': fone = r.text\n",
    "\n",
    "            name = htmlPage.find('h1',{'class':'section-hero-header-title-title GLOBAL__gm2-headline-5'})\n",
    "            if name != None and name.find('span') != None: name = name.find('span').text\n",
    "            details = htmlPage.find('button',{'jsaction':'pane.rating.category'})\n",
    "            if details != None: details = details.text\n",
    "            classification = htmlPage.find('span',{'class':'section-star-display'})\n",
    "            if classification != None: classification = classification.text\n",
    "\n",
    "            return {'classification': classification, 'position': position, 'name': name, 'fone': fone, 'address': address, 'link': link, 'details': details}\n",
    "    \n",
    "    def findSocialMediaAccounts(self, data_business, print_process=True):\n",
    "        ''' recebe uma lista ou dataframe e procura pelas redes sociais em seus sites'''\n",
    "        business_df = data_business\n",
    "\n",
    "        assert str(type(business_df)) == \"<class 'pandas.core.frame.DataFrame'>\", 'o input deve ser um pandas.dataframe'\n",
    "\n",
    "        for row, link in business_df[business_df['link'].isnull() == False]['link'].T.iteritems():\n",
    "            try:\n",
    "                req = requests.get(link)\n",
    "                if req.status_code == 200:\n",
    "                    htmlPage = bs4.BeautifulSoup(req.content, features='html.parser', from_encoding=\"iso-8859-1\")\n",
    "\n",
    "                    business_df.loc[row, 'has_instagram'] = True if str(req.content).find('instagram') != -1 else False\n",
    "                    business_df.loc[row, 'has_facebook'] = True if str(req.content).find('facebook') != -1 else False\n",
    "\n",
    "                    for link in htmlPage.find_all('a'):\n",
    "                        if link.get('href') != None and 'facebook' in link.get('href'):\n",
    "                            business_df.loc[row, 'facebook_link'] = link.get('href')\n",
    "                        elif link.get('href') != None and 'instagram' in link.get('href'):\n",
    "                            business_df.loc[row, 'instagram_link'] = link.get('href')\n",
    "\n",
    "                    if print_process == True and row % 100 == 0:\n",
    "                        print('{} processed'.format(row))\n",
    "                else:\n",
    "                    business_df.loc[row, 'link_problem'] = True \n",
    "            except Exception as error:\n",
    "                business_df.loc[row, 'link_problem'] = True\n",
    "        return business_df\n",
    "    \n",
    "    def getInstagramData(self, data_business, print_process=True, clean=True):\n",
    "        ''' Ira pegar os dados gerais das contas de Instagram encontradas '''\n",
    "        data = data_business\n",
    "\n",
    "        assert str(type(data)) == \"<class 'pandas.core.frame.DataFrame'>\", 'o input deve ser um pandas.dataframe'    \n",
    "        # verifica se ha navegador aberto, se nao houver ira abrir\n",
    "        try:\n",
    "            self.driver.current_url\n",
    "        except Exception as error: \n",
    "            if 'chrome not reachable' or 'HTTPConnectionPool' in str(error):\n",
    "                self.driver_()\n",
    "\n",
    "        for row, link in data[data['instagram_link'].isnull() == False]['instagram_link'].T.iteritems():\n",
    "            first_w = data.loc[row]['instagram_link'].find('w')\n",
    "            content = data.loc[row]['instagram_link']\n",
    "            data.loc[row]['instagram_link'] = 'https://' + content[first_w:]\n",
    "            \n",
    "            try:\n",
    "                self.driver.get(link)\n",
    "                htmlPage = bs4.BeautifulSoup(self.driver.page_source, features='html.parser', from_encoding=\"iso-8859-1\")\n",
    "\n",
    "                # PEGA OS DADOS NUMERICOS DA PAGINA\n",
    "                numbers = htmlPage.find_all('a', {'class':'-nal3'})\n",
    "                if numbers != None:\n",
    "                    data.loc[row, 'instagram_posts'] = numbers[0].text\n",
    "                    data.loc[row, 'instagram_followers'] = numbers[1].text\n",
    "                    data.loc[row, 'instagram_following'] = numbers[2].text\n",
    "\n",
    "                #PEGA OS DADOS DE TEXTO DA PAGINA\n",
    "                data_text = htmlPage.find('div', {'class':'-vDIg'})\n",
    "                page_name = data_text.find('h1', {'class':'rhpdm'})\n",
    "                if page_name != None: data.loc[row, 'instagram_page_name'] = page_name.text\n",
    "                bio_text = data_text.find('span')   \n",
    "                if bio_text != None: data.loc[row, 'instagram_bio_text'] = bio_text.text\n",
    "                link = data_text.find('a',{'class':'yLUwa'})\n",
    "                if link != None: data.loc[row, 'instagram_bio_link'] = link.get('href')\n",
    "                username = htmlPage.find('h2', {'class':'_7UhW9'})\n",
    "                if username != None: data.loc[row, 'instagram_username'] = username.text\n",
    "\n",
    "                if print_process == True: print('getting Instagram Data, {} processed, last username saved: {}'.format(row, username.text))\n",
    "                time.sleep(1)\n",
    "            except Exception as error:\n",
    "                if 'IndexError' in str(type(error)):\n",
    "                    unavilable = htmlPage.find('div',{'class':'_07DZ3'})\n",
    "                    data.loc[row, 'instagram_link_problem'] = True if unavilable != None and \"Sorry, this page isn't available.\" in unavilable.text else None\n",
    "                    continue \n",
    "                else:\n",
    "                    data.loc[row, 'instagram_link_problem'] = '404'\n",
    "        \n",
    "        if clean == False:\n",
    "            return data\n",
    "        else:\n",
    "            clean = ProcessData()\n",
    "            return clean.cleanInstagramData(data)\n",
    "        \n",
    "    def getFacebookData(self, data_business, print_process=True, clean=True):\n",
    "        ''' Ira pegar os dados gerais das contas de Facebook encontradas '''\n",
    "        data = data_business\n",
    "\n",
    "        assert str(type(data)) == \"<class 'pandas.core.frame.DataFrame'>\", 'o input deve ser um pandas.dataframe'    \n",
    "        # verifica se ha navegador aberto, se nao houver ira abrir\n",
    "        try:\n",
    "            self.driver.current_url\n",
    "        except Exception as error: \n",
    "            if 'chrome not reachable' or 'HTTPConnectionPool' in str(error):\n",
    "                self.driver_()\n",
    "        \n",
    "        for row, link in data[data['facebook_link'].isnull() == False]['facebook_link'].T.iteritems():\n",
    "            try:\n",
    "                self.driver.get(link)\n",
    "                htmlPage = bs4.BeautifulSoup(self.driver.page_source, features='html.parser')\n",
    "\n",
    "                facebook_page_name = htmlPage.find('span', {'class':'_33vv'})\n",
    "                if facebook_page_name != None: data.loc[row, 'facebook_page_name'] = facebook_page_name.text\n",
    "\n",
    "                facebook_page_user = htmlPage.find('a', {'class':'_2wmb'})\n",
    "                if facebook_page_user != None: data.loc[row, 'facebook_page_user'] = facebook_page_user.text\n",
    "\n",
    "                page_data = htmlPage.find('div', {'class':'_4-u2 _6590 _3xaf _4-u8'})\n",
    "                \n",
    "                if page_data != None:\n",
    "                    saved = []\n",
    "                    for div in page_data.find_all('div'):\n",
    "                        if div.text not in saved:\n",
    "                            if 'follow' in div.text or 'seguindo ' in div.text:\n",
    "                                data.loc[row, 'facebook_followers'] = div.text\n",
    "                            elif 'like' in div.text or 'curtiram' in div.text:\n",
    "                                data.loc[row, 'facebook_likes'] = div.text\n",
    "                            elif 'check' in div.text:\n",
    "                                data.loc[row, 'check-ins'] = div.text\n",
    "                else:\n",
    "                    data.loc[row, 'facebook_link_problem'] = True\n",
    "\n",
    "                about_content = htmlPage.find('div', {'class':'_4-u2 _u9q _3xaf _4-u8'})\n",
    "                data.loc[row, 'about_content'] = str(about_content)\n",
    "\n",
    "                time.sleep(1)\n",
    "                if print_process == True: print('getting Facebook Data, {} processed'.format(row))\n",
    "            except Exception as error:\n",
    "                print(type(error), print(error))\n",
    "                data.loc[row, 'facebook_link_problem'] = True\n",
    "\n",
    "        if clean == False:\n",
    "            return data\n",
    "        else:\n",
    "            clean = ProcessData()\n",
    "            return clean.cleanFacebookData(data)\n",
    "        \n",
    "    def getAdsData(self, data_business, print_process=True, clean=True):\n",
    "        ''' Ira pegar os dados de anuncios encontrados '''\n",
    "        self.dataAds = data_business\n",
    "        \n",
    "        assert str(type(data_business)) == \"<class 'pandas.core.frame.DataFrame'>\", 'o input deve ser um pandas.dataframe'    \n",
    "        # verifica se ha navegador aberto, se nao houver ira abrir\n",
    "        try:\n",
    "            sp.driver.current_url\n",
    "        except Exception as error: \n",
    "            if 'chrome not reachable' or 'HTTPConnectionPool' in str(error):\n",
    "                sp.driver_()\n",
    "\n",
    "        sp.driver.get('https://pt-br.facebook.com/ads/library')\n",
    "        time.sleep(1)\n",
    "\n",
    "        for row, content in self.dataAds.loc[(self.dataAds['facebook_page_name'].isnull() == False)][['facebook_page_name', 'facebook_page_user']].T.iteritems():\n",
    "            clicked = self.searchPageName(content['facebook_page_name'], content['facebook_page_user'])\n",
    "            \n",
    "            if clicked == False: \n",
    "                self.dataAds.loc[row, 'ads_page_problem'] = '404' #rodou todos os resultados e nao encontrou a pagina\n",
    "            elif clicked == True or clicked == 'By_page_name':\n",
    "                if not(self.getDataAdsPage(row)): \n",
    "                    self.dataAds.loc[row, 'ads_page_problem'] = True #por alguma razao nao encontrou os dados\n",
    "                elif clicked == 'By_page_name':\n",
    "                    self.dataAds.loc[row, 'ads_page_problem'] = 'By_page_name'\n",
    "\n",
    "                time.sleep(1)\n",
    "                print('{} pages processed'.format(row))\n",
    "        \n",
    "        if clean == False:\n",
    "            return self.dataAds\n",
    "        else:\n",
    "            clean = ProcessData()\n",
    "            return clean.cleanAdsData(self.dataAds)\n",
    "\n",
    "    def clickInPageResultList(self, facebook_page_info, by_page_name=False):\n",
    "        '''\n",
    "            procura a pagina na lista de resultados e se algum resultado na lista tiver o mesmo @usuario ira clicar\n",
    "        '''\n",
    "\n",
    "        div_to_find = '_8t5z' if by_page_name == False else '_7h1e'\n",
    "        results = sp.driver.find_elements_by_class_name(div_to_find)\n",
    "\n",
    "        if results != None:\n",
    "            for result in results:\n",
    "                content_to_verify = result.text[:result.text.find(' ')] if by_page_name == False else result.text\n",
    "                # se nao for pelo nome da pagina, ira pegar o nome de usuario que esta no inicio do texto\n",
    "\n",
    "                if facebook_page_info == content_to_verify:\n",
    "                    result.click()\n",
    "                    time.sleep(3)\n",
    "                    return True\n",
    "            return False\n",
    "        else:\n",
    "            return 'Not Found'\n",
    "\n",
    "    def searchPageName(self, facebook_page_name, facebook_page_user):\n",
    "        '''\n",
    "            Recebe uma pagina e seu nome_de_usuario e pesquisa na biblioteca de anuncio\n",
    "        '''\n",
    "        try:\n",
    "            search_box = sp.driver.find_element_by_class_name('_7hgq')\n",
    "            search_box.click()\n",
    "\n",
    "            for char in search_box.get_attribute('value'):\n",
    "                search_box.send_keys(Keys.BACKSPACE)\n",
    "                #apaga qualquer conteudo escrito na barra de pesquisa\n",
    "\n",
    "            search_box.send_keys(facebook_page_name)\n",
    "            time.sleep(2)\n",
    "\n",
    "            clicked = self.clickInPageResultList(facebook_page_user)\n",
    "\n",
    "            # SE NAO ENCONTROU A PAGINA NA LISTA IRA VERIFICAR SE HA OPCAO VER MAIS E SE ESTA MAIS ABAIXO NOS RESULTADOS\n",
    "            if clicked == False:\n",
    "                try:\n",
    "                    more_results = more_results = sp.driver.find_element_by_class_name('_7h65')\n",
    "                    more_results.click()\n",
    "                    time.sleep(1)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                if self.clickInPageResultList(facebook_page_user):\n",
    "                    return True\n",
    "                else:\n",
    "                    # se ainda assim nao encontrar a pagina ira tentar pelo nome da pagina\n",
    "                    if self.clickInPageResultList(facebook_page_name, by_page_name=True):\n",
    "                        return 'By_page_name'\n",
    "                    else:\n",
    "                        False\n",
    "            else:\n",
    "                return True\n",
    "        except Exception as error:\n",
    "            print('error in: [searchPageName]: \\n')\n",
    "            print(type(error), error)\n",
    "            return 'Error'\n",
    "\n",
    "    def getDataAdsPage(self, dataframe_row):\n",
    "        htmlPage = bs4.BeautifulSoup(sp.driver.page_source, features='html.parser')\n",
    "        self.dataAds.loc[dataframe_row, 'library_ads_url'] = sp.driver.current_url\n",
    "        time.sleep(1)\n",
    "\n",
    "        active_ads = htmlPage.find('div',{'class':'_7gn2'})\n",
    "        if active_ads != None: self.dataAds.loc[dataframe_row, 'active_ads'] = active_ads.text\n",
    "\n",
    "        page_data = htmlPage.find('div',{'class':'_3-8- _3qn7 _61-0 _2fyh _3qnf'})\n",
    "        if page_data != None:\n",
    "            for row_in_list in page_data.find_all('div'):\n",
    "                # percorre as linhas ate encontrar o icone de pagina criada ira pegar o conteudo\n",
    "                if row_in_list.find('i', {'class': 'img sp_9Pca48nsujv sx_50d5dd'}) != None: \n",
    "                    created_in = row_in_list.find('span',{'class':'_3-99'})\n",
    "                    if created_in != None: self.dataAds.loc[dataframe_row, 'created_in'] = created_in.text\n",
    "                    return True\n",
    "                else:\n",
    "                    self.dataAds.loc[dataframe_row, 'created_in'] = '404' #por alguma razao nao encontrou os dados entao ira retornar False\n",
    "        else:\n",
    "            self.dataAds.loc[dataframe_row, 'created_in'] = '404' #por alguma razao nao encontrou os dados entao ira retornar False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessData():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def googleSearchResults(self, results_list):\n",
    "        ''' * reomocao de duplicatos pelo endereco '''\n",
    "        \n",
    "        self.data = [] #sera o dataframe com os dados\n",
    "        \n",
    "        #recebe a lista de resultados do google e processa os dados\n",
    "        for count, r in enumerate(results_list):\n",
    "            name = r.find('h3', {'class':'section-result-title'})\n",
    "            if name != None: name = name.text\n",
    "            address = r.find('span', {'class':'section-result-location'})\n",
    "            if address != None: address = address.text\n",
    "            details = r.find('span', {'class':'section-result-details'})\n",
    "            if details != None: details = details.text\n",
    "            fone = r.find('span', {'class':'section-result-info section-result-phone-number'})\n",
    "            if fone != None: fone = fone.text\n",
    "            link = r.find('a')\n",
    "            if link != None: link = link.get('href')\n",
    "            classification = r.find('span', {'class':'cards-rating-score'})\n",
    "            if classification != None: classification = classification.text\n",
    "\n",
    "            data_result = {'classification': classification, 'position': count+1, 'name': name, 'fone': fone, 'address': address, 'link': link, 'details': details}\n",
    "            self.data.append(data_result)\n",
    "    \n",
    "        self.data = pd.DataFrame(self.data)\n",
    "        self.data.drop_duplicates(['address']) \n",
    "        self.data.reset_index(drop=True, inplace=True)\n",
    "        return self.data\n",
    "    \n",
    "    def cleanInstagramData(self, business_df):\n",
    "        ''' Limpa os dados coletados do Instagram '''\n",
    "        data_instagram_page = business_df\n",
    "        assert str(type(data_instagram_page)) == \"<class 'pandas.core.frame.DataFrame'>\", 'o input deve ser um pandas.dataframe'    \n",
    "\n",
    "        for row, content in data_instagram_page[data_instagram_page.instagram_followers.isnull() == False].T.iteritems():\n",
    "            data_instagram_page.loc[row, 'instagram_posts'] = self.processQntOnString(content['instagram_posts'][:content['instagram_posts'].find(' ')].replace(',', ''))\n",
    "            data_instagram_page.loc[row, 'instagram_followers'] = self.processQntOnString(content['instagram_followers'][:content['instagram_followers'].find(' ')].replace(',', '.'))\n",
    "            data_instagram_page.loc[row, 'instagram_following'] = self.processQntOnString(content['instagram_following'][:content['instagram_following'].find(' ')].replace(',', '.'))\n",
    "        return data_instagram_page\n",
    "\n",
    "    def processQntOnString(self, qnt_string):\n",
    "        '''\n",
    "            Nas quantidade podera contar 'k' ou 'm' para mil ou milhoes\n",
    "        '''\n",
    "        try:\n",
    "            key = ''.join(filter(str.isalpha, qnt_string))\n",
    "            total_chars = '0'*6 if key == 'm' else '0'*3 if key == 'k' else '0'*3 if key == 'mil' else '0'*6 if key == 'mi' else None  \n",
    "\n",
    "            if total_chars != None and key in qnt_string and '.' in qnt_string:\n",
    "                #verifica quantos numeros apos o ponto flutuante e retira essa quantidade de zeros\n",
    "                total_chars = total_chars[len(qnt_string[qnt_string.find('.')+1:qnt_string.find('m')]):]\n",
    "                qnt_string = qnt_string.replace(key, total_chars).replace('.','')\n",
    "                return int(qnt_string)\n",
    "            elif total_chars != None and key in qnt_string:\n",
    "                qnt_string = qnt_string.replace(key, total_chars)\n",
    "                return int(qnt_string)\n",
    "            else:\n",
    "                return int(qnt_string.replace('.', ''))\n",
    "        except:\n",
    "            return 'Error in value: {}'.format(qnt_string)\n",
    "        \n",
    "    def cleanFacebookData(self, data_business):\n",
    "        data_facacebook_page = data_business\n",
    "        for row, content in data_facacebook_page[data_facacebook_page.facebook_page_name.isnull() == False].T.iteritems():\n",
    "            if str(content['facebook_likes']) != 'nan': data_facacebook_page.loc[row, 'facebook_likes'] = int(content['facebook_likes'][:content['facebook_likes'].find(' ')].replace(',', '').replace('.', ''))\n",
    "            if str(content['facebook_followers']) != 'nan': data_facacebook_page.loc[row, 'facebook_followers'] = int(content['facebook_followers'][:content['facebook_followers'].find(' ')].replace(',', '').replace('.', ''))\n",
    "            if str(content['check-ins']) != 'nan': data_facacebook_page.loc[row, 'check-ins'] = int(content['check-ins'][:content['check-ins'].find(' ')].replace(',', '').replace('.', ''))\n",
    "        \n",
    "        return data_facacebook_page\n",
    "    \n",
    "    def cleanAdsData(self, data_business):\n",
    "        ads_data = data_business\n",
    "        \n",
    "        assert str(type(ads_data)) == \"<class 'pandas.core.frame.DataFrame'>\", 'o input deve ser um pandas.dataframe'    \n",
    "        \n",
    "        months = {'Jan': '01', 'Fev': '02', 'Mar': '03', 'Abr': '04', 'Maio': '05', 'Mai': '05', 'Jun': '06', \n",
    "                 'Jul': '07', 'Ago': '08', 'Set': '09', 'Out': '10', 'Nov': '11', 'Dez': '12'}\n",
    "        \n",
    "        for row, content in ads_data.loc[(ads_data.active_ads.isnull() == False)][['active_ads', 'created_in']].T.iteritems():\n",
    "            try:\n",
    "                ads_data.loc[row, 'active_ads'] = int(''.join(filter(str.isdigit, content['active_ads'])))\n",
    "            except TypeError: \n",
    "                pass\n",
    "            try:\n",
    "                data_ = content['created_in'].replace(' de ', '/')\n",
    "                month_str = data_.split('/')[1]\n",
    "                print(month_str)\n",
    "                ads_data.loc[row, 'created_in'] = pd.to_datetime(data_.replace(month_str, months[month_str]))\n",
    "\n",
    "            except Exception as error:\n",
    "                print('ERROR IN ROW ({}) [socialMediaScrapper()] function: cleanAdsData()\\n'.format(row))\n",
    "                print(type(error), str(error))\n",
    "                \n",
    "        return data_business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:211: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "c:\\users\\yan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\bs4\\__init__.py:177: UserWarning:\n",
      "\n",
      "You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting Instagram Data, 0 processed, last username saved: clinica.curitiba\n",
      "getting Instagram Data, 1 processed, last username saved: chcufpr\n",
      "getting Instagram Data, 2 processed, last username saved: chcufpr\n",
      "getting Instagram Data, 5 processed, last username saved: clinicameitan\n",
      "getting Instagram Data, 6 processed, last username saved: paranaclinicas\n",
      "getting Instagram Data, 11 processed, last username saved: otorrinoclinica\n",
      "getting Instagram Data, 17 processed, last username saved: policlinica_sitio_cercado_ofc\n",
      "getting Instagram Data, 28 processed, last username saved: cendicor_cendicorbaby\n",
      "getting Instagram Data, 30 processed, last username saved: ortopediasete\n",
      "getting Instagram Data, 33 processed, last username saved: neoderme\n",
      "getting Instagram Data, 34 processed, last username saved: clinicalosangelescuritiba\n",
      "getting Instagram Data, 38 processed, last username saved: oftalmocuritiba\n",
      "getting Instagram Data, 40 processed, last username saved: clinica_cardiocare\n",
      "getting Instagram Data, 41 processed, last username saved: ortopediahauer\n",
      "getting Instagram Data, 43 processed, last username saved: fundacaoprorenal\n",
      "getting Instagram Data, 56 processed, last username saved: maxiclin\n",
      "getting Instagram Data, 59 processed, last username saved: clinicadefraturastorres\n",
      "getting Instagram Data, 74 processed, last username saved: hospitalportoseguro\n",
      "getting Instagram Data, 87 processed, last username saved: ortopediasete\n",
      "getting Instagram Data, 89 processed, last username saved: clinicasercuritiba\n",
      "getting Instagram Data, 90 processed, last username saved: clinica.cedip\n",
      "getting Instagram Data, 91 processed, last username saved: one.curitiba\n",
      "getting Instagram Data, 95 processed, last username saved: peleclin\n",
      "getting Instagram Data, 96 processed, last username saved: clinicacepelle\n",
      "getting Instagram Data, 97 processed, last username saved: clinicaprevenirbrasil\n",
      "getting Instagram Data, 98 processed, last username saved: chcufpr\n",
      "getting Instagram Data, 100 processed, last username saved: prodentalcuritiba\n",
      "getting Instagram Data, 106 processed, last username saved: nutri_marimaciel\n",
      "getting Instagram Data, 122 processed, last username saved: chcufpr\n",
      "getting Instagram Data, 123 processed, last username saved: dracarolineobrali\n",
      "getting Instagram Data, 131 processed, last username saved: paranaclinicas\n",
      "getting Instagram Data, 135 processed, last username saved: chcufpr\n",
      "getting Instagram Data, 139 processed, last username saved: clinicaconcebercuritiba\n",
      "getting Instagram Data, 150 processed, last username saved: odontocompany\n",
      "getting Instagram Data, 153 processed, last username saved: clinica.curitiba\n",
      "getting Instagram Data, 154 processed, last username saved: clinicaintento\n",
      "getting Instagram Data, 157 processed, last username saved: clinica.dapi\n",
      "getting Instagram Data, 160 processed, last username saved: clinica_ident\n",
      "getting Instagram Data, 161 processed, last username saved: nossodentistacuritiba_\n",
      "getting Instagram Data, 163 processed, last username saved: clinicabellage\n",
      "getting Instagram Data, 164 processed, last username saved: oftalmoplastica\n",
      "getting Instagram Data, 166 processed, last username saved: clinica.dapi\n",
      "getting Instagram Data, 168 processed, last username saved: amorsaudebrasil\n",
      "getting Instagram Data, 170 processed, last username saved: acruzeirodosul\n",
      "getting Instagram Data, 173 processed, last username saved: clinica.dapi\n",
      "getting Instagram Data, 176 processed, last username saved: caetano_marchesini\n",
      "getting Instagram Data, 181 processed, last username saved: clinica_ident\n",
      "getting Instagram Data, 182 processed, last username saved: nossodentistacuritiba_\n",
      "getting Instagram Data, 184 processed, last username saved: clinicabellage\n",
      "getting Instagram Data, 185 processed, last username saved: oftalmoplastica\n",
      "getting Instagram Data, 187 processed, last username saved: clinica.dapi\n",
      "getting Instagram Data, 189 processed, last username saved: amorsaudebrasil\n",
      "getting Instagram Data, 191 processed, last username saved: acruzeirodosul\n",
      "getting Instagram Data, 194 processed, last username saved: clinica.dapi\n",
      "getting Instagram Data, 197 processed, last username saved: rdicuritiba\n",
      "getting Instagram Data, 200 processed, last username saved: wavemedicinafetal\n",
      "getting Instagram Data, 204 processed, last username saved: odontocompany\n",
      "getting Instagram Data, 209 processed, last username saved: amorsaudebrasil\n",
      "getting Instagram Data, 210 processed, last username saved: boa_pisada\n",
      "getting Instagram Data, 219 processed, last username saved: clinica.cedip\n",
      "getting Instagram Data, 224 processed, last username saved: institutodeoncologiapr\n",
      "getting Instagram Data, 227 processed, last username saved: ijo.med\n",
      "getting Instagram Data, 232 processed, last username saved: tellestransplantecapilar\n",
      "getting Instagram Data, 233 processed, last username saved: institutodeoncologiapr\n",
      "getting Instagram Data, 234 processed, last username saved: maxiclin\n",
      "getting Instagram Data, 235 processed, last username saved: equilibrio_e_bem_estar_cwb\n",
      "getting Instagram Data, 236 processed, last username saved: faicalodontologia\n",
      "getting Instagram Data, 245 processed, last username saved: imunizzare\n",
      "getting Instagram Data, 257 processed, last username saved: hospitalbarigui\n",
      "getting Instagram Data, 260 processed, last username saved: perfecttaodonto\n",
      "getting Instagram Data, 264 processed, last username saved: indic.diagnosticos\n",
      "getting Instagram Data, 265 processed, last username saved: anaclinsjp\n",
      "getting Instagram Data, 269 processed, last username saved: paranaclinicas\n",
      "getting Instagram Data, 270 processed, last username saved: tipclinica\n",
      "getting Instagram Data, 272 processed, last username saved: hospitalportoseguro\n",
      "getting Instagram Data, 273 processed, last username saved: dasa.oficial\n",
      "getting Instagram Data, 279 processed, last username saved: oraluniccuritiba\n",
      "getting Instagram Data, 281 processed, last username saved: ndnucleodiagnostico\n",
      "getting Instagram Data, 290 processed, last username saved: immef\n",
      "getting Instagram Data, 291 processed, last username saved: unibrasil\n",
      "getting Instagram Data, 294 processed, last username saved: geneseclinica\n",
      "getting Instagram Data, 297 processed, last username saved: dentaluni\n",
      "getting Instagram Data, 299 processed, last username saved: carmocentromedico\n",
      "getting Instagram Data, 300 processed, last username saved: oftalmocuritiba\n",
      "getting Instagram Data, 301 processed, last username saved: fetalmedcuritiba\n",
      "getting Instagram Data, 304 processed, last username saved: clinica.dapi\n",
      "getting Instagram Data, 306 processed, last username saved: uroclinicacuritiba\n",
      "getting Instagram Data, 307 processed, last username saved: curitiba_pmc\n",
      "getting Instagram Data, 309 processed, last username saved: clinicasajustar\n",
      "getting Instagram Data, 310 processed, last username saved: magrassoficial\n",
      "getting Instagram Data, 312 processed, last username saved: cendicor_cendicorbaby\n",
      "getting Instagram Data, 314 processed, last username saved: paranaclinicas\n",
      "getting Instagram Data, 320 processed, last username saved: curitiba_pmc\n",
      "getting Instagram Data, 321 processed, last username saved: fetalmedcuritiba\n",
      "getting Instagram Data, 324 processed, last username saved: clinica.dapi\n",
      "getting Instagram Data, 326 processed, last username saved: uroclinicacuritiba\n",
      "getting Instagram Data, 327 processed, last username saved: curitiba_pmc\n",
      "getting Instagram Data, 329 processed, last username saved: clinicasajustar\n",
      "getting Instagram Data, 330 processed, last username saved: magrassoficial\n",
      "getting Instagram Data, 332 processed, last username saved: cendicor_cendicorbaby\n",
      "getting Instagram Data, 334 processed, last username saved: paranaclinicas\n",
      "getting Instagram Data, 347 processed, last username saved: clinicaluxcuritiba\n",
      "getting Instagram Data, 348 processed, last username saved: laboratorio.fa\n",
      "getting Instagram Data, 349 processed, last username saved: laboratorio.fa\n",
      "getting Instagram Data, 352 processed, last username saved: laboratorio.fa\n",
      "getting Instagram Data, 355 processed, last username saved: fleury\n",
      "getting Instagram Data, 359 processed, last username saved: odontocompany\n",
      "getting Instagram Data, 367 processed, last username saved: clinicaluxcuritiba\n",
      "getting Instagram Data, 368 processed, last username saved: laboratorio.fa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting Instagram Data, 369 processed, last username saved: laboratorio.fa\n",
      "getting Instagram Data, 372 processed, last username saved: laboratorio.fa\n",
      "getting Instagram Data, 375 processed, last username saved: fleury\n",
      "getting Instagram Data, 382 processed, last username saved: hnsgcuritiba\n",
      "getting Instagram Data, 386 processed, last username saved: unimedcuritibaoficial\n",
      "getting Instagram Data, 389 processed, last username saved: magrassoficial\n",
      "getting Instagram Data, 391 processed, last username saved: odontocompany\n",
      "getting Instagram Data, 393 processed, last username saved: hnsgcuritiba\n",
      "getting Instagram Data, 394 processed, last username saved: magrassoficial\n",
      "getting Instagram Data, 396 processed, last username saved: cvrveterinaria\n",
      "getting Instagram Data, 397 processed, last username saved: magrassoficial\n"
     ]
    }
   ],
   "source": [
    "# sp = socialMediaScrapper()\n",
    "# saude_curitiba = sp.googleSearch()\n",
    "# saude_curitiba = sp.findSocialMediaAccounts(saude_curitiba)\n",
    "saude_curitiba = sp.getInstagramData(saude_curitiba)\n",
    "# saude_curitiba = sp.getFacebookData(saude_curitiba)\n",
    "# saude_curitiba = sp.getAdsData(saude_curitiba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>classification</th>\n",
       "      <th>details</th>\n",
       "      <th>fone</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>position</th>\n",
       "      <th>has_instagram</th>\n",
       "      <th>has_facebook</th>\n",
       "      <th>facebook_link</th>\n",
       "      <th>instagram_link</th>\n",
       "      <th>link_problem</th>\n",
       "      <th>instagram_posts</th>\n",
       "      <th>instagram_followers</th>\n",
       "      <th>instagram_following</th>\n",
       "      <th>instagram_page_name</th>\n",
       "      <th>instagram_bio_text</th>\n",
       "      <th>instagram_bio_link</th>\n",
       "      <th>instagram_username</th>\n",
       "      <th>instagram_link_problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alameda J√∫lia da Costa, 1447</td>\n",
       "      <td>4,7</td>\n",
       "      <td>Centro m√©dico</td>\n",
       "      <td>(41) 3240-2900 ¬∑</td>\n",
       "      <td>http://curitiba.clinicaadventista.org.br/</td>\n",
       "      <td>Cl√≠nica Adventista de Curitiba</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.facebook.com/clinica.curitiba</td>\n",
       "      <td>https://www.instagram.com/clinica.curitiba/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143</td>\n",
       "      <td>589</td>\n",
       "      <td>828</td>\n",
       "      <td>Cl√≠nica Adventista de Curitiba</td>\n",
       "      <td>üë®üèª‚Äç‚öïÔ∏è Consultas, exames e procedimentos‚≠ê Mais ...</td>\n",
       "      <td>https://l.instagram.com/?u=http%3A%2F%2Fcuriti...</td>\n",
       "      <td>clinica.curitiba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R. Pasteur, 26</td>\n",
       "      <td>3,9</td>\n",
       "      <td>Cl√≠nica oftalmol√≥gica</td>\n",
       "      <td>(41) 3523-0082 ¬∑</td>\n",
       "      <td>http://www.hc.ufpr.br/</td>\n",
       "      <td>UFPR - Centro de Vis√£o do Hospital de Cl√≠nicas</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.facebook.com/chcufpr</td>\n",
       "      <td>https://www.instagram.com/chcufpr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265</td>\n",
       "      <td>5489</td>\n",
       "      <td>8</td>\n",
       "      <td>Complexo HC UFPR</td>\n",
       "      <td>Perfil Oficial do Complexo Hospital de Cl√≠nica...</td>\n",
       "      <td>https://l.instagram.com/?u=http%3A%2F%2Ffacebo...</td>\n",
       "      <td>chcufpr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R. Gen. Carneiro, 181</td>\n",
       "      <td>4,7</td>\n",
       "      <td>Cl√≠nica da sa√∫de da mulher</td>\n",
       "      <td>(41) 3360-1800 ¬∑</td>\n",
       "      <td>http://www.hc.ufpr.br/</td>\n",
       "      <td>Maternidade Do Hospital De Cl√≠nicas</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.facebook.com/chcufpr</td>\n",
       "      <td>https://www.instagram.com/chcufpr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265</td>\n",
       "      <td>5489</td>\n",
       "      <td>8</td>\n",
       "      <td>Complexo HC UFPR</td>\n",
       "      <td>Perfil Oficial do Complexo Hospital de Cl√≠nica...</td>\n",
       "      <td>https://l.instagram.com/?u=http%3A%2F%2Ffacebo...</td>\n",
       "      <td>chcufpr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R. Dr. Raul Carneiro Filho, 328</td>\n",
       "      <td>4,9</td>\n",
       "      <td>Policl√≠nica</td>\n",
       "      <td>(41) 3333-3322 ¬∑</td>\n",
       "      <td>http://www.clinicamedicamaisvida.com.br/</td>\n",
       "      <td>Cl√≠nica M√©dica Mais Vida</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Av. Luiz Xavier, 68</td>\n",
       "      <td>3,2</td>\n",
       "      <td>Cl√≠nica oftalmol√≥gica</td>\n",
       "      <td>(41) 3322-9537 ¬∑</td>\n",
       "      <td>http://www.clinicatijucas.com.br/</td>\n",
       "      <td>CL√çNICA TIJUCAS Cl√≠nica de Oftalmologia e Gine...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           address classification                     details  \\\n",
       "0     Alameda J√∫lia da Costa, 1447            4,7               Centro m√©dico   \n",
       "1                   R. Pasteur, 26            3,9       Cl√≠nica oftalmol√≥gica   \n",
       "2            R. Gen. Carneiro, 181            4,7  Cl√≠nica da sa√∫de da mulher   \n",
       "3  R. Dr. Raul Carneiro Filho, 328            4,9                 Policl√≠nica   \n",
       "4              Av. Luiz Xavier, 68            3,2       Cl√≠nica oftalmol√≥gica   \n",
       "\n",
       "                 fone                                       link  \\\n",
       "0   (41) 3240-2900 ¬∑   http://curitiba.clinicaadventista.org.br/   \n",
       "1   (41) 3523-0082 ¬∑                      http://www.hc.ufpr.br/   \n",
       "2   (41) 3360-1800 ¬∑                      http://www.hc.ufpr.br/   \n",
       "3   (41) 3333-3322 ¬∑    http://www.clinicamedicamaisvida.com.br/   \n",
       "4   (41) 3322-9537 ¬∑           http://www.clinicatijucas.com.br/   \n",
       "\n",
       "                                                name  position has_instagram  \\\n",
       "0                     Cl√≠nica Adventista de Curitiba         1          True   \n",
       "1     UFPR - Centro de Vis√£o do Hospital de Cl√≠nicas         2          True   \n",
       "2                Maternidade Do Hospital De Cl√≠nicas         3          True   \n",
       "3                           Cl√≠nica M√©dica Mais Vida         4         False   \n",
       "4  CL√çNICA TIJUCAS Cl√≠nica de Oftalmologia e Gine...         5         False   \n",
       "\n",
       "  has_facebook                              facebook_link  \\\n",
       "0         True  https://www.facebook.com/clinica.curitiba   \n",
       "1         True           https://www.facebook.com/chcufpr   \n",
       "2         True           https://www.facebook.com/chcufpr   \n",
       "3         True                                        NaN   \n",
       "4        False                                        NaN   \n",
       "\n",
       "                                instagram_link link_problem instagram_posts  \\\n",
       "0  https://www.instagram.com/clinica.curitiba/          NaN             143   \n",
       "1            https://www.instagram.com/chcufpr          NaN             265   \n",
       "2            https://www.instagram.com/chcufpr          NaN             265   \n",
       "3                                          NaN          NaN             NaN   \n",
       "4                                          NaN          NaN             NaN   \n",
       "\n",
       "  instagram_followers instagram_following             instagram_page_name  \\\n",
       "0                 589                 828  Cl√≠nica Adventista de Curitiba   \n",
       "1                5489                   8                Complexo HC UFPR   \n",
       "2                5489                   8                Complexo HC UFPR   \n",
       "3                 NaN                 NaN                             NaN   \n",
       "4                 NaN                 NaN                             NaN   \n",
       "\n",
       "                                  instagram_bio_text  \\\n",
       "0  üë®üèª‚Äç‚öïÔ∏è Consultas, exames e procedimentos‚≠ê Mais ...   \n",
       "1  Perfil Oficial do Complexo Hospital de Cl√≠nica...   \n",
       "2  Perfil Oficial do Complexo Hospital de Cl√≠nica...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                  instagram_bio_link instagram_username  \\\n",
       "0  https://l.instagram.com/?u=http%3A%2F%2Fcuriti...   clinica.curitiba   \n",
       "1  https://l.instagram.com/?u=http%3A%2F%2Ffacebo...            chcufpr   \n",
       "2  https://l.instagram.com/?u=http%3A%2F%2Ffacebo...            chcufpr   \n",
       "3                                                NaN                NaN   \n",
       "4                                                NaN                NaN   \n",
       "\n",
       "   instagram_link_problem  \n",
       "0                     NaN  \n",
       "1                     NaN  \n",
       "2                     NaN  \n",
       "3                     NaN  \n",
       "4                     NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saude_curitiba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saude_curitiba.to_csv('./Saved Data/Curitiba/saude.csv', index=None)\n",
    "\n",
    "with_ads_page = data[data.active_ads.isnull() == False]\n",
    "with_ads_page = with_ads_page.drop(['classification', 'has_instagram','has_facebook', 'link_problem','instagram_link_problem', 'instagram_bio_text','instagram_bio_link', 'facebook_link_problem', 'about_content', 'library_ads_url', 'ads_page_problem'], axis=1)\n",
    "with_ads_page.sort_values(by=['instagram_posts'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "saude_curitiba.to_excel('./Saved Data/Curitiba/saude.xls', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "prints inline:\n",
    "\n",
    " * Incluir print output inline para funcao que esta fazendo request para todos os sites em busca das redes sociais\n",
    " * para os instagrans e facebook que ja foram processados/encontrados\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saude_curitiba = pd.DataFrame(saude_curitiba)\n",
    "# saude_curitiba.reset_index(drop=True, inplace=True)\n",
    "# saude_curitiba.to_csv('./Saved Data/Curitiba/saude.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
