{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import bs4, time, requests\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('imobiliarias_curitiba_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path='./webdriver/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.google.com/maps/search/imobili%C3%A1rias+em+Curitiba,+PR/@-25.4419502,-49.3636112,12z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pega todos os resultados do google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "while True:\n",
    "    htmlPage = bs4.BeautifulSoup(driver.page_source, features='html.parser')\n",
    "    results.extend(htmlPage.find_all('div', {'class':'section-result'}))\n",
    "    \n",
    "    button_status = htmlPage.find('button', {'jstcache':'347'}).get('disabled')\n",
    "    if button_status == 'true':\n",
    "        print('end')\n",
    "        break\n",
    "    \n",
    "    next_page = driver.find_element_by_class_name('n7lv7yjyC35__button-next-icon')\n",
    "    next_page.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "results = list(set(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrai os dados da lista de resultados do google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for count, r in enumerate(results):\n",
    "    name = r.find('h3', {'class':'section-result-title'}).text\n",
    "    address = r.find('span', {'class':'section-result-location'}).text\n",
    "    details = r.find('span', {'class':'section-result-details'}).text\n",
    "    fone = r.find('span', {'jstcache':'167'}).text\n",
    "    link = r.find('a').get('href')\n",
    "    \n",
    "    data_result = {'name': name, 'fone': fone, 'address': address, 'link': link, 'details': details}\n",
    "    data.append(data_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.39% de 391 Imobiliarias em Curitiba não possuem site\n"
     ]
    }
   ],
   "source": [
    "without_website = data[data['link'].isnull() == True]\n",
    "print('{}% de {} Imobiliarias em Curitiba não possuem site'.format(round(len(without_website)/len(data)*100, 2), len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pega os links para as redes sociais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    }
   ],
   "source": [
    "for row, link in data[data['link'].isnull() == False]['link'].T.iteritems():\n",
    "    try:\n",
    "        req = requests.get(link)\n",
    "        if req.status_code == 200:\n",
    "            htmlPage = bs4.BeautifulSoup(req.content, features='html.parser')\n",
    "            \n",
    "            data.loc[row, 'has_instagram'] = True if str(req.content).find('instagram') != -1 else False\n",
    "            data.loc[row, 'has_facebook'] = True if str(req.content).find('facebook') != -1 else False\n",
    "            \n",
    "            for link in htmlPage.find_all('a'):\n",
    "                if link.get('href') != None and 'facebook' in link.get('href'):\n",
    "                    data.loc[row, 'facebook_link'] = link.get('href')\n",
    "                elif link.get('href') != None and 'instagram' in link.get('href'):\n",
    "                    data.loc[row, 'instagram_link'] = link.get('href')\n",
    "            \n",
    "            if row % 100 == 0: \n",
    "                print('{} processed'.format(row))\n",
    "        else:\n",
    "            data.loc[row, 'link_problem'] = True \n",
    "    except Exception as error:\n",
    "        data.loc[row, 'link_problem'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pega os dados do instagram das que tiveram os links encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path='./webdriver/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 processed, last username saved: corteze.imoveis\n",
      "111 processed, last username saved: corteze.imoveis\n",
      "144 processed, last username saved: corteze.imoveis\n",
      "276 processed, last username saved: gold.imoveis.curitiba\n",
      "117 processed, last username saved: corteze.imoveis\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for row, link in data[data['instagram_link'].isnull() == False]['instagram_link'].T.iteritems():\n",
    "# for row, link in data.loc[bad_links]['instagram_link'].T.iteritems():\n",
    "    first_w = data.loc[row]['instagram_link'].find('w')\n",
    "    content = data.loc[row]['instagram_link']\n",
    "    data.loc[row]['instagram_link'] = 'https://' + content[first_w:]\n",
    "    \n",
    "    try:\n",
    "        driver.get(link)\n",
    "        htmlPage = bs4.BeautifulSoup(driver.page_source, features='html.parser')\n",
    "\n",
    "        # PEGA OS DADOS NUMERICOS DA PAGINA\n",
    "        numbers = htmlPage.find_all('a', {'class':'-nal3'})\n",
    "        if numbers != None:\n",
    "            data.loc[row, 'instagram_posts'] = numbers[0].text\n",
    "            data.loc[row, 'instagram_followers'] = numbers[1].text\n",
    "            data.loc[row, 'instagram_following'] = numbers[2].text\n",
    "\n",
    "\n",
    "        #PEGA OS DADOS DE TEXTO DA PAGINA\n",
    "        data_text = htmlPage.find('div', {'class':'-vDIg'})\n",
    "\n",
    "        page_name = data_text.find('h1', {'class':'rhpdm'})\n",
    "        if page_name != None: data.loc[row, 'instagram_page_name'] = page_name.text\n",
    "\n",
    "        bio_text = data_text.find('span')   \n",
    "        if bio_text != None: data.loc[row, 'instagram_bio_text'] = bio_text.text\n",
    "\n",
    "        link = data_text.find('a',{'class':'yLUwa'})\n",
    "        if link != None: data.loc[row, 'instagram_bio_link'] = link.get('href')\n",
    "\n",
    "        username = htmlPage.find('h2', {'class':'_7UhW9'})\n",
    "        if username != None: data.loc[row, 'instagram_username'] = username.text\n",
    "\n",
    "        print('{} processed, last username saved: {}'.format(row, username.text))\n",
    "        time.sleep(1)\n",
    "        if row % 19 == 0:\n",
    "            print('waiting for 5 seconds...\\n')\n",
    "            time.sleep(5)\n",
    "    except Exception as error:\n",
    "        if 'IndexError' in str(type(error)):\n",
    "            unavilable = htmlPage.find('div',{'class':'_07DZ3'})\n",
    "            data.loc[row, 'instagram_link_problem'] = True if unavilable != None and \"Sorry, this page isn't available.\" in unavilable.text else None\n",
    "            continue \n",
    "        \n",
    "        errors.append(row)\n",
    "        bad_links = list(set(errors))\n",
    "        print('error in line {}'.format(row))\n",
    "        print(type(error), str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pega os dados do Facebook das paginas encontradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 processed\n",
      "1 processed\n",
      "5 processed\n",
      "7 processed\n",
      "8 processed\n",
      "10 processed\n",
      "12 processed\n",
      "15 processed\n",
      "18 processed\n",
      "22 processed\n",
      "24 processed\n",
      "25 processed\n",
      "27 processed\n",
      "28 processed\n",
      "29 processed\n",
      "32 processed\n",
      "35 processed\n",
      "41 processed\n",
      "44 processed\n",
      "45 processed\n",
      "46 processed\n",
      "47 processed\n",
      "48 processed\n",
      "50 processed\n",
      "54 processed\n",
      "55 processed\n",
      "56 processed\n",
      "58 processed\n",
      "62 processed\n",
      "63 processed\n",
      "67 processed\n",
      "68 processed\n",
      "69 processed\n",
      "70 processed\n",
      "71 processed\n",
      "72 processed\n",
      "75 processed\n",
      "76 processed\n",
      "79 processed\n",
      "81 processed\n",
      "89 processed\n",
      "90 processed\n",
      "93 processed\n",
      "95 processed\n",
      "97 processed\n",
      "100 processed\n",
      "101 processed\n",
      "105 processed\n",
      "106 processed\n",
      "error in line 111\n",
      "<class 'selenium.common.exceptions.InvalidArgumentException'> Message: invalid argument\n",
      "  (Session info: chrome=83.0.4103.61)\n",
      "\n",
      "116 processed\n",
      "error in line 117\n",
      "<class 'selenium.common.exceptions.InvalidArgumentException'> Message: invalid argument\n",
      "  (Session info: chrome=83.0.4103.61)\n",
      "\n",
      "118 processed\n",
      "119 processed\n",
      "120 processed\n",
      "121 processed\n",
      "error in line 122\n",
      "<class 'selenium.common.exceptions.InvalidArgumentException'> Message: invalid argument\n",
      "  (Session info: chrome=83.0.4103.61)\n",
      "\n",
      "123 processed\n",
      "124 processed\n",
      "127 processed\n",
      "128 processed\n",
      "129 processed\n",
      "error in line 130\n",
      "<class 'selenium.common.exceptions.InvalidArgumentException'> Message: invalid argument\n",
      "  (Session info: chrome=83.0.4103.61)\n",
      "\n",
      "132 processed\n",
      "134 processed\n",
      "135 processed\n",
      "137 processed\n",
      "139 processed\n",
      "141 processed\n",
      "143 processed\n",
      "error in line 144\n",
      "<class 'selenium.common.exceptions.InvalidArgumentException'> Message: invalid argument\n",
      "  (Session info: chrome=83.0.4103.61)\n",
      "\n",
      "146 processed\n",
      "149 processed\n",
      "151 processed\n",
      "155 processed\n",
      "158 processed\n",
      "161 processed\n",
      "162 processed\n",
      "163 processed\n",
      "164 processed\n",
      "169 processed\n",
      "171 processed\n",
      "173 processed\n",
      "177 processed\n",
      "180 processed\n",
      "181 processed\n",
      "185 processed\n",
      "187 processed\n",
      "188 processed\n",
      "193 processed\n",
      "194 processed\n",
      "196 processed\n",
      "199 processed\n",
      "201 processed\n",
      "204 processed\n",
      "205 processed\n",
      "206 processed\n",
      "208 processed\n",
      "209 processed\n",
      "213 processed\n",
      "217 processed\n",
      "219 processed\n",
      "221 processed\n",
      "225 processed\n",
      "229 processed\n",
      "230 processed\n",
      "231 processed\n",
      "234 processed\n",
      "237 processed\n",
      "240 processed\n",
      "242 processed\n",
      "244 processed\n",
      "246 processed\n",
      "249 processed\n",
      "254 processed\n",
      "256 processed\n",
      "257 processed\n",
      "259 processed\n",
      "260 processed\n",
      "263 processed\n",
      "264 processed\n",
      "267 processed\n",
      "269 processed\n",
      "271 processed\n",
      "274 processed\n",
      "275 processed\n",
      "276 processed\n",
      "277 processed\n",
      "278 processed\n",
      "279 processed\n",
      "281 processed\n",
      "283 processed\n",
      "284 processed\n",
      "285 processed\n",
      "error in line 288\n",
      "<class 'selenium.common.exceptions.InvalidArgumentException'> Message: invalid argument\n",
      "  (Session info: chrome=83.0.4103.61)\n",
      "\n",
      "290 processed\n",
      "291 processed\n",
      "292 processed\n",
      "295 processed\n",
      "296 processed\n",
      "297 processed\n",
      "301 processed\n",
      "305 processed\n",
      "306 processed\n",
      "309 processed\n",
      "310 processed\n",
      "311 processed\n",
      "312 processed\n",
      "313 processed\n",
      "314 processed\n",
      "317 processed\n",
      "326 processed\n",
      "327 processed\n",
      "328 processed\n",
      "329 processed\n",
      "333 processed\n",
      "339 processed\n",
      "341 processed\n",
      "342 processed\n",
      "346 processed\n",
      "347 processed\n",
      "348 processed\n",
      "351 processed\n",
      "353 processed\n",
      "356 processed\n",
      "358 processed\n",
      "359 processed\n",
      "363 processed\n",
      "364 processed\n",
      "368 processed\n",
      "369 processed\n",
      "370 processed\n",
      "372 processed\n",
      "373 processed\n",
      "375 processed\n",
      "376 processed\n",
      "378 processed\n",
      "380 processed\n",
      "384 processed\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "# count = 0\n",
    "for row, link in data[data['facebook_link'].isnull() == False]['facebook_link'].T.iteritems():\n",
    "#     count+=1\n",
    "#     if count >= 10: break\n",
    "\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        htmlPage = bs4.BeautifulSoup(driver.page_source, features='html.parser')\n",
    "\n",
    "        facebook_page_name = htmlPage.find('span', {'class':'_33vv'})\n",
    "        if facebook_page_name != None: data.loc[row, 'facebook_page_name'] = facebook_page_name.text\n",
    "\n",
    "        facebook_page_user = htmlPage.find('a', {'class':'_2wmb'})\n",
    "        if facebook_page_user != None: data.loc[row, 'facebook_page_user'] = facebook_page_user.text\n",
    "\n",
    "        page_data = htmlPage.find('div', {'class':'_4-u2 _6590 _3xaf _4-u8'})\n",
    "        if page_data != None:\n",
    "            saved = []\n",
    "            for div in page_data.find_all('div'):\n",
    "                if div.text not in saved:\n",
    "                    if 'follow' in div.text:\n",
    "                        data.loc[row, 'facebook_followers'] = div.text\n",
    "                    elif 'like' in div.text:\n",
    "                        data.loc[row, 'facebook_likes'] = div.text\n",
    "                    elif 'check' in div.text:\n",
    "                        data.loc[row, 'check-ins'] = div.text\n",
    "        else:\n",
    "            data.loc[row, 'facebook_link_problem'] = True\n",
    "\n",
    "        about_content = htmlPage.find('div', {'class':'_4-u2 _u9q _3xaf _4-u8'})\n",
    "        data.loc[row, 'about_content'] = str(about_content)\n",
    "\n",
    "        time.sleep(1)\n",
    "        print('{} processed'.format(row))\n",
    "    except Exception as error:\n",
    "        data.loc[row, 'facebook_link_problem'] = True\n",
    "        \n",
    "        errors.append(row)\n",
    "        bad_links = list(set(errors))\n",
    "        print('error in line {}'.format(row))\n",
    "        print(type(error), str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ira pesquisar quais empresas anunciam e quais nao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clickInPageResultList(facebook_page_info, by_page_name=False):\n",
    "    '''\n",
    "        procura a pagina na lista de resultados e se algum resultado na lista tiver o mesmo @usuario ira clicar\n",
    "    '''\n",
    "    \n",
    "    div_to_find = '_8t5z' if by_page_name == False else '_7h1e'\n",
    "    results = driver.find_elements_by_class_name(div_to_find)\n",
    "    \n",
    "    if results != None:\n",
    "        for result in results:\n",
    "            content_to_verify = result.text[:result.text.find(' ')] if by_page_name == False else result.text\n",
    "            # se nao for pelo nome da pagina, ira pegar o nome de usuario que esta no inicio do texto\n",
    "            \n",
    "            if facebook_page_info == content_to_verify:\n",
    "                result.click()\n",
    "                time.sleep(3)\n",
    "                return True\n",
    "        return False\n",
    "    else:\n",
    "        return 'Not Found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchPageName(facebook_page_name, facebook_page_user):\n",
    "    '''\n",
    "        Recebe uma pagina e seu nome_de_usuario e pesquisa na biblioteca de anuncio\n",
    "    '''\n",
    "    try:\n",
    "        search_box = driver.find_element_by_class_name('_7hgq')\n",
    "        search_box.click()\n",
    "\n",
    "        for char in search_box.get_attribute('value'):\n",
    "            search_box.send_keys(Keys.BACKSPACE)\n",
    "            #apaga qualquer conteudo escrito na barra de pesquisa\n",
    "\n",
    "        search_box.send_keys(facebook_page_name)\n",
    "        time.sleep(2)\n",
    "\n",
    "        clicked = clickInPageResultList(facebook_page_user)\n",
    "\n",
    "        # SE NAO ENCONTROU A PAGINA NA LISTA IRA VERIFICAR SE HA OPCAO VER MAIS E SE ESTA MAIS ABAIXO NOS RESULTADOS\n",
    "        if clicked == False:\n",
    "            try:\n",
    "                more_results = more_results = driver.find_element_by_class_name('_7h65')\n",
    "                more_results.click()\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            if clickInPageResultList(facebook_page_user):\n",
    "                return True\n",
    "            else:\n",
    "                # se ainda assim nao encontrar a pagina ira tentar pelo nome da pagina\n",
    "                if clickInPageResultList(facebook_page_name, by_page_name=True):\n",
    "                    return 'By_page_name'\n",
    "                else:\n",
    "                    False\n",
    "        else:\n",
    "            return True\n",
    "    except Exception as error:\n",
    "        print('error in: [searchPageName]: \\n')\n",
    "        print(type(error), error)\n",
    "        return 'Error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataAdsPage(dataframe_row):\n",
    "    '''\n",
    "        Ira pegar os dados da pagina de anuncio e salvar no dataframe\n",
    "    '''\n",
    "    htmlPage = bs4.BeautifulSoup(driver.page_source, features='html.parser')\n",
    "    data.loc[dataframe_row, 'library_ads_url'] = driver.current_url\n",
    "    time.sleep(1)\n",
    "\n",
    "    active_ads = htmlPage.find('div',{'class':'_7gn2'})\n",
    "    if active_ads != None: data.loc[dataframe_row, 'active_ads'] = active_ads.text\n",
    "\n",
    "    page_data = htmlPage.find('div',{'class':'_3-8- _3qn7 _61-0 _2fyh _3qnf'})\n",
    "    for row_in_list in page_data.find_all('div'):\n",
    "        # percorre as linhas ate encontrar o icone de pagina criada ira pegar o conteudo\n",
    "        if row_in_list.find('i', {'class': 'img sp_MZcK2Ebngod sx_fa0899'}) != None: \n",
    "            created_in = row_in_list.find('span',{'class':'_3-99'})\n",
    "            if created_in != None: data.loc[dataframe_row, 'created_in'] = created_in.text\n",
    "            return True\n",
    "    return False #por alguma razao nao encontrou os dados entao ira retornar False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 pages processed\n",
      "70 pages processed\n",
      "72 pages processed\n",
      "89 pages processed\n",
      "177 pages processed\n",
      "180 pages processed\n",
      "201 pages processed\n",
      "219 pages processed\n",
      "240 pages processed\n",
      "242 pages processed\n",
      "283 pages processed\n",
      "347 pages processed\n",
      "368 pages processed\n",
      "369 pages processed\n",
      "384 pages processed\n"
     ]
    }
   ],
   "source": [
    "driver.get('https://pt-br.facebook.com/ads/library')\n",
    "time.sleep(1)\n",
    "for row, facebook_page_name in data[(data['facebook_page_name'].isnull() == False) & (data['active_ads'].isnull() == True)]['facebook_page_name'].T.iteritems():\n",
    "    facebook_page_user = data.loc[row, 'facebook_page_user']\n",
    "    clicked = searchPageName(facebook_page_name, facebook_page_user)\n",
    "    \n",
    "    if clicked == False: \n",
    "        data.loc[row, 'ads_page_problem'] = 'Not Found' #rodou todos os resultados e nao encontrou a pagina\n",
    "    elif clicked == True or clicked == 'By_page_name':\n",
    "        if not(getDataAdsPage(row)): \n",
    "            data.loc[row, 'ads_page_problem'] = True #por alguma razao nao encontrou os dados\n",
    "        elif clicked == 'By_page_name':\n",
    "            data.loc[row, 'ads_page_problem'] = 'By_page_name'\n",
    "        \n",
    "        time.sleep(1)\n",
    "        print('{} pages processed'.format(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('imobiliarias_curitiba_full.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path='./webdriver/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
